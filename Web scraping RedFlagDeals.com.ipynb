{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping the redflagdeals forum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import requests # Scraping\n",
    "from bs4 import BeautifulSoup # HTML parsing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving data from the \"Hot Deals - All Categories\" sub-forum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Page format: `url/page#/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL base, current page, and total number of pages. Used to iterate over page URLs.\n",
    "current_page = \"\" # page number used to format base URL\n",
    "total_pages = 0 # total number for endpoint of iteration\n",
    "page_url = \"https://forums.redflagdeals.com/hot-deals-f9/\" # base url for \"Hot Deals\"\n",
    "\n",
    "# URL base to generate links to specific posts\n",
    "base_url = \"https://forums.redflagdeals.com\"\n",
    "\n",
    "# Dataframe to store scraped data\n",
    "# gloale keyword allows modification in function\n",
    "table = pd.DataFrame(columns=\n",
    "    ['title',\n",
    "    'votes',\n",
    "    'source',\n",
    "    'creation_date',\n",
    "    'last_reply',\n",
    "    'author',\n",
    "    'replies',\n",
    "    'views',\n",
    "    'price',\n",
    "    'saving',\n",
    "    'expiry',\n",
    "    'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts(page: str):\n",
    "    \"\"\"Returns list of all HTML post elements found on page\"\"\"\n",
    "    \n",
    "    # Initalize list of posts on page class=\"row topic\"\n",
    "    posts = []\n",
    "    \n",
    "    # Get entire page content\n",
    "    response = requests.get(page)\n",
    "    content = response.content\n",
    "\n",
    "    # URL parser\n",
    "    parser = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # Find total number of pages\n",
    "    # Format of text: \" {current page #} of {total page #} \"\n",
    "    # Need to strip white space and extract total page #\n",
    "    pages = parser.select(\".pagination_menu_trigger\")[0].text.strip().split(\"of \")[1]\n",
    "    total_pages = int(pages)\n",
    "    \n",
    "    # Find and return list of topics\n",
    "    topics = parser.find_all(\"li\", class_=\"row topic\")\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_info(post: str) -> dict:\n",
    "    \"\"\"Extracts and returns additional information from a specific post:\n",
    "    url-link to the deal, the price, the discount percentage, and the expiry date\n",
    "    if available\"\"\"\n",
    "    \n",
    "    # Additional information about deal\n",
    "    add = {}\n",
    "    \n",
    "    # Get content of post\n",
    "    response = requests.get(post)\n",
    "    content = response.content\n",
    "    \n",
    "    # Parse URL\n",
    "    parser = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # Offer-summary field: may contain deal link, price, saving, and retailer\n",
    "    summary = parser.select(\".post_offer_fields\") # format example: \"Price:\\n$200\\nSaving:\\n70%\"\n",
    "    try:\n",
    "        summary_list = summary[0].text.split(\"\\n\") \n",
    "    except: summary_list = []\n",
    "        \n",
    "    # Go through summary elements and save relevant information\n",
    "    for i in range(1, (len(summary_list) -1), 2): # index 0 is empty string\n",
    "        current_element = summary_list[i] # content of current list element\n",
    "        next_element = summary_list[i+1] # next list element\n",
    "        \n",
    "        # Price, saving, and expiry date information contained in the next list element will be saved\n",
    "        if current_element.startswith(\"Price\") or current_element.startswith(\"Saving\") or current_element.startswith(\"Expiry\"):\n",
    "            add[current_element]  = next_element # next elements corrsponds to content\n",
    "            \n",
    "    # URL to link\n",
    "    try: \n",
    "        url = str(summary[0]).split('href=\"')[1].split('\"')[0] # select link between href=\" and \"\n",
    "        add['Link:'] = url\n",
    "    except: add['Link:'] = np.nan\n",
    "        \n",
    "    \n",
    "    # If any of the elements is not found in the field add None value to dictionary \n",
    "    if \"Price:\" not in add:\n",
    "        add['Price:'] = np.nan\n",
    "        \n",
    "    if \"Savings:\" not in add:\n",
    "        add['Savings:'] = np.nan\n",
    "        \n",
    "    if \"Expiry:\" not in add:\n",
    "        add['Expiry:'] = np.nan\n",
    "    \n",
    "    return add # Return dictionary containing with information on price, saving and expiry  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_table(posts: list) -> None:\n",
    "    '''Fills table with data from elements of the post objects'''\n",
    "    \n",
    "    # For appending data \n",
    "    tmp_table = pd.DataFrame() # temporary DataFrame that holds all column objects. Will be appended to the global `table`. \n",
    "    \n",
    "    # Initializing columns for tmp_table\n",
    "    title_col = pd.Series()\n",
    "    source_col = pd.Series()\n",
    "    url_col = pd.Series()\n",
    "    votes_col = pd.Series()\n",
    "    replies_col = pd.Series()\n",
    "    views_col = pd.Series()\n",
    "    creation_date_col = pd.Series()\n",
    "    last_reply_col = pd.Series()\n",
    "    author_col = pd.Series()\n",
    "    price_col = pd.Series()\n",
    "    saving_col = pd.Series()\n",
    "    expiry_col = pd.Series()\n",
    "    \n",
    "\n",
    "    # Iterate through post elements and extract data for table\n",
    "    for post in posts:\n",
    "        \n",
    "        # Retailer corresponding to deal\n",
    "        try: \n",
    "            source = post.select(\".topictitle_retailer\")[0].text.split(\"\\n\")[0] # split and remove line-break characters\n",
    "            source_series = pd.Series(source) # transform into Series object\n",
    "        except: source_series = pd.Series(np.nan)\n",
    "        source_col = source_col.append(source_series, ignore_index=True) # append to column and ignore index to avoid complications when merging with DataFrame object\n",
    "\n",
    "        # Number of votes\n",
    "        try: \n",
    "            votes = post.select(\".post_voting\")[0].text.split(\"\\n\")[1] # split and remove line-break characters\n",
    "            votes_series = pd.Series(votes) # transform into Series object\n",
    "        except: votes_series = pd.Series(0)\n",
    "        votes_col = votes_col.append(votes_series, ignore_index=True) # append to column\n",
    "            \n",
    "        # Title \n",
    "        try:\n",
    "            topic = post.select(\".topic_title_link\") # contains title and sub-url to post\n",
    "            title = topic[0].text.split('\\n')[1] # extract text and remove line-break characters\n",
    "            title_series = pd.Series(title)\n",
    "        except: title_series = pd.Series(np.nan)\n",
    "        title_col = title_col.append(title_series, ignore_index=True)\n",
    "\n",
    "        # Date of initial posting\n",
    "        try: \n",
    "            creation = post.select(\".first-post-time\")[0].text.split(\"\\n\")[0] # remove line-breaks\n",
    "            creation_series = pd.Series(creation)\n",
    "        except: creation_series = pd.Series(np.nan)\n",
    "        creation_date_col = creation_date_col.append(creation_series, ignore_index=True) # append to column\n",
    "        \n",
    "        # Date of most recent replie\n",
    "        try: \n",
    "            last_replie = post.select(\".last-post-time\")[0].text.split(\"\\n\")[0] # remove line-breaks\n",
    "            last_replie_series = pd.Series(last_replie)\n",
    "        except: last_replie_series = pd.Series(np.nan)\n",
    "        last_reply_col = last_reply_col.append(last_replie_series, ignore_index=True) # append to column\n",
    "        \n",
    "        # Author user-name\n",
    "        try:\n",
    "            author = post.select(\".thread_meta_author\")[0].text.split(\"\\n\")[0]\n",
    "            author_series = pd.Series(author)\n",
    "        except: author_series = pd.Series(np.nan)\n",
    "        author_col = author_col.append(author_series, ignore_index=True)\n",
    "        \n",
    "        \n",
    "        # Number of replies\n",
    "        try:\n",
    "            replies = post.select(\".posts\")[0].text.split(\"\\n\")[0]\n",
    "            replies = replies.replace(\",\",\"\") # replace any commas to prepare for data type switch to integer\n",
    "            replies_series = pd.Series(replies)\n",
    "        except: replies_series = pd.Series(np.nan)\n",
    "        replies_col = replies_col.append(replies_series, ignore_index=True)\n",
    "        \n",
    "        # Number of views\n",
    "        try:\n",
    "            views = post.select(\".views\")[0].text.split(\"\\n\")[0]\n",
    "            views = views.replace(\",\",\"\") # replace any commas to prepare for data type switch to integer\n",
    "            views_series = pd.Series(views)\n",
    "        except: replies_series = pd.Series(np.nan)\n",
    "        views_col = views_col.append(views_series, ignore_index=True)\n",
    "        \n",
    "        # Link to current post\n",
    "        try:\n",
    "            link = str(topic).split('href=\"')[1] # split at href to extract link\n",
    "            link_clean = link.split('\">')[0] # remove superfluous characters\n",
    "        except: \n",
    "            link_clean = np.nan\n",
    "        \n",
    "        # Additional information post\n",
    "        if link_clean != None: # retrieve information from post, if it exists\n",
    "            post_url = (base_url + \"{}\").format(link_clean) # merge base-, and sub-url to generate the complete post-link\n",
    "            add_info = additional_info(post_url) # get additonal information on price, saving, and expiry-date\n",
    "            \n",
    "            # Fill columns with additional information from add_info dictionary\n",
    "            price_col = price_col.append(pd.Series(add_info['Price:']), ignore_index=True)\n",
    "            saving_col = saving_col.append(pd.Series(add_info['Savings:']), ignore_index=True)\n",
    "            expiry_col = expiry_col.append(pd.Series(add_info['Expiry:']), ignore_index=True)\n",
    "            url_col = url_col.append(pd.Series(add_info['Link:']), ignore_index=True)\n",
    "        else:\n",
    "            price_col = price_col.append(np.nan)\n",
    "            saving_col = saving_col.append(np.nan)\n",
    "            expiry_col = expiry_col.append(np.nan)\n",
    "            url_col = url_col.append(np.nan)\n",
    "        \n",
    "            \n",
    "    # Fill temporary table\n",
    "    tmp_table['title'] = title_col\n",
    "    tmp_table['votes'] = votes_col.astype(int)\n",
    "    tmp_table['source'] = source_col\n",
    "    tmp_table['creation_date'] = creation_date_col\n",
    "    tmp_table['last_reply'] = last_reply_col\n",
    "    tmp_table['author'] = author_col\n",
    "    tmp_table['replies'] = replies_col.astype(int)\n",
    "    tmp_table['views'] = views_col.astype(int)\n",
    "    tmp_table['price'] = price_col\n",
    "    tmp_table['saving'] = saving_col\n",
    "    tmp_table['expiry'] = expiry_col\n",
    "    tmp_table['url'] = url_col\n",
    "        \n",
    "    # Print result\n",
    "    global table # gloabal keyword allows modification inside function\n",
    "    table = table.append(tmp_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>votes</th>\n",
       "      <th>source</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_reply</th>\n",
       "      <th>author</th>\n",
       "      <th>replies</th>\n",
       "      <th>views</th>\n",
       "      <th>price</th>\n",
       "      <th>saving</th>\n",
       "      <th>expiry</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nokia 5.3 $349</td>\n",
       "      <td>2</td>\n",
       "      <td>Amazon.ca</td>\n",
       "      <td>Jul 11th, 2020 10:49 pm</td>\n",
       "      <td>Jul 11th, 2020 11:28 pm</td>\n",
       "      <td>markolic</td>\n",
       "      <td>3</td>\n",
       "      <td>811</td>\n",
       "      <td>350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.amazon.ca/gp/redirect.html?ie=UTF8&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Garage Epoxy $214.99</td>\n",
       "      <td>21</td>\n",
       "      <td>Costco</td>\n",
       "      <td>Jun 29th, 2020 12:30 pm</td>\n",
       "      <td>Jul 11th, 2020 11:27 pm</td>\n",
       "      <td>pux420</td>\n",
       "      <td>108</td>\n",
       "      <td>33004</td>\n",
       "      <td>214.99</td>\n",
       "      <td>20%</td>\n",
       "      <td>July 12, 2020</td>\n",
       "      <td>https://www.costco.ca/rokrez-epoxy-floor-coati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>$25.99 AUKEY 10000mAh Power Bank, 18W USB-C Po...</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon.ca</td>\n",
       "      <td>Jul 11th, 2020 11:26 pm</td>\n",
       "      <td>Jul 11th, 2020 11:26 pm</td>\n",
       "      <td>Strychinine</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>25.99</td>\n",
       "      <td>48%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.amazon.ca/gp/redirect.html?ie=UTF8&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Amazon Fire HD 8 (newest edition) live on July...</td>\n",
       "      <td>-2</td>\n",
       "      <td>The Source</td>\n",
       "      <td>Jul 10th, 2020 3:43 pm</td>\n",
       "      <td>Jul 11th, 2020 11:23 pm</td>\n",
       "      <td>mikea</td>\n",
       "      <td>31</td>\n",
       "      <td>5725</td>\n",
       "      <td>89.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.kqzyfj.com/click-749547-10797598?ur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Breyer's Creamery Style Ice Cream 1.66L $2.99 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>No Frills</td>\n",
       "      <td>Jul 11th, 2020 7:34 pm</td>\n",
       "      <td>Jul 11th, 2020 11:21 pm</td>\n",
       "      <td>Strafe1</td>\n",
       "      <td>14</td>\n",
       "      <td>1349</td>\n",
       "      <td>2.99/10.99</td>\n",
       "      <td>$3/$5</td>\n",
       "      <td>July 15, 2020</td>\n",
       "      <td>https://www.nofrills.ca/print-flyer?utm_campai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Google Home Wifi Router (1st gen) $129.97 in s...</td>\n",
       "      <td>3</td>\n",
       "      <td>Staples</td>\n",
       "      <td>Jul 11th, 2020 4:09 pm</td>\n",
       "      <td>Jul 11th, 2020 11:18 pm</td>\n",
       "      <td>SAN66</td>\n",
       "      <td>19</td>\n",
       "      <td>3228</td>\n",
       "      <td>$129.97</td>\n",
       "      <td>30%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://staplescanada.4u8mqw.net/c/341376/7554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>$499.99 Acer Aspire 3 Ryzen 3 3200U / 8GB RAM ...</td>\n",
       "      <td>20</td>\n",
       "      <td>Shoppers Drug Mart</td>\n",
       "      <td>Jul 10th, 2020 4:40 pm</td>\n",
       "      <td>Jul 11th, 2020 11:17 pm</td>\n",
       "      <td>mangoman</td>\n",
       "      <td>157</td>\n",
       "      <td>18128</td>\n",
       "      <td>$499 + 20x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>July 12, 2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Ryobi Gasoline Backpack Blower YMMV</td>\n",
       "      <td>-2</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>Jul 11th, 2020 3:15 pm</td>\n",
       "      <td>Jul 11th, 2020 11:14 pm</td>\n",
       "      <td>HarelD475</td>\n",
       "      <td>15</td>\n",
       "      <td>2507</td>\n",
       "      <td>$125</td>\n",
       "      <td>Reg. $288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://the-home-depot-ca.pxf.io/c/341376/5836...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Quickjack 7000slx $200 off - $1300</td>\n",
       "      <td>25</td>\n",
       "      <td>Costco</td>\n",
       "      <td>Jul 6th, 2020 9:56 am</td>\n",
       "      <td>Jul 11th, 2020 11:14 pm</td>\n",
       "      <td>hkhorace</td>\n",
       "      <td>60</td>\n",
       "      <td>11815</td>\n",
       "      <td>1300</td>\n",
       "      <td>$200 off</td>\n",
       "      <td>July 12, 2020</td>\n",
       "      <td>https://www.costco.ca/quickjack-bl-7000slx-318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Amex Personal Platinum offer - $250 credits fo...</td>\n",
       "      <td>144</td>\n",
       "      <td>American Express</td>\n",
       "      <td>Jun 4th, 2020 3:44 am</td>\n",
       "      <td>Jul 11th, 2020 11:14 pm</td>\n",
       "      <td>bigfishman</td>\n",
       "      <td>542</td>\n",
       "      <td>82081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>August 27, 2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title votes  \\\n",
       "0                                     nokia 5.3 $349     2   \n",
       "1                               Garage Epoxy $214.99    21   \n",
       "2  $25.99 AUKEY 10000mAh Power Bank, 18W USB-C Po...     0   \n",
       "3  Amazon Fire HD 8 (newest edition) live on July...    -2   \n",
       "4  Breyer's Creamery Style Ice Cream 1.66L $2.99 ...     2   \n",
       "5  Google Home Wifi Router (1st gen) $129.97 in s...     3   \n",
       "6  $499.99 Acer Aspire 3 Ryzen 3 3200U / 8GB RAM ...    20   \n",
       "7                Ryobi Gasoline Backpack Blower YMMV    -2   \n",
       "8                 Quickjack 7000slx $200 off - $1300    25   \n",
       "9  Amex Personal Platinum offer - $250 credits fo...   144   \n",
       "\n",
       "               source            creation_date               last_reply  \\\n",
       "0           Amazon.ca  Jul 11th, 2020 10:49 pm  Jul 11th, 2020 11:28 pm   \n",
       "1              Costco  Jun 29th, 2020 12:30 pm  Jul 11th, 2020 11:27 pm   \n",
       "2           Amazon.ca  Jul 11th, 2020 11:26 pm  Jul 11th, 2020 11:26 pm   \n",
       "3          The Source   Jul 10th, 2020 3:43 pm  Jul 11th, 2020 11:23 pm   \n",
       "4           No Frills   Jul 11th, 2020 7:34 pm  Jul 11th, 2020 11:21 pm   \n",
       "5             Staples   Jul 11th, 2020 4:09 pm  Jul 11th, 2020 11:18 pm   \n",
       "6  Shoppers Drug Mart   Jul 10th, 2020 4:40 pm  Jul 11th, 2020 11:17 pm   \n",
       "7          Home Depot   Jul 11th, 2020 3:15 pm  Jul 11th, 2020 11:14 pm   \n",
       "8              Costco    Jul 6th, 2020 9:56 am  Jul 11th, 2020 11:14 pm   \n",
       "9    American Express    Jun 4th, 2020 3:44 am  Jul 11th, 2020 11:14 pm   \n",
       "\n",
       "        author replies  views       price     saving           expiry  \\\n",
       "0     markolic       3    811         350        NaN              NaN   \n",
       "1       pux420     108  33004      214.99        20%    July 12, 2020   \n",
       "2  Strychinine       0     72       25.99        48%              NaN   \n",
       "3        mikea      31   5725       89.99        NaN              NaN   \n",
       "4      Strafe1      14   1349  2.99/10.99      $3/$5    July 15, 2020   \n",
       "5        SAN66      19   3228     $129.97        30%              NaN   \n",
       "6     mangoman     157  18128  $499 + 20x        NaN    July 12, 2020   \n",
       "7    HarelD475      15   2507        $125  Reg. $288              NaN   \n",
       "8     hkhorace      60  11815        1300   $200 off    July 12, 2020   \n",
       "9   bigfishman     542  82081         NaN        NaN  August 27, 2020   \n",
       "\n",
       "                                                 url  \n",
       "0  http://www.amazon.ca/gp/redirect.html?ie=UTF8&...  \n",
       "1  https://www.costco.ca/rokrez-epoxy-floor-coati...  \n",
       "2  http://www.amazon.ca/gp/redirect.html?ie=UTF8&...  \n",
       "3  http://www.kqzyfj.com/click-749547-10797598?ur...  \n",
       "4  https://www.nofrills.ca/print-flyer?utm_campai...  \n",
       "5  https://staplescanada.4u8mqw.net/c/341376/7554...  \n",
       "6                                                NaN  \n",
       "7  https://the-home-depot-ca.pxf.io/c/341376/5836...  \n",
       "8  https://www.costco.ca/quickjack-bl-7000slx-318...  \n",
       "9                                                NaN  "
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of posts\n",
    "posts = get_posts(url)\n",
    "\n",
    "# Test\n",
    "fill_table(posts)\n",
    "\n",
    "table.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
