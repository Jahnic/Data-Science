{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping of RedFlagDeals.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RedFlagDeals.com is a forum where users can post sales or deals that they have come accross. This first part of the project is focused on scraping relevant information from the \"All Hot Deals\" section, which includes all product categories. In the second and third part I will clean and visualize the data to display interesting deals.  \n",
    "\n",
    "|Column name|Description|\n",
    "|---|---|\n",
    "|'title'| Title of post|\n",
    "|'votes'| Sum of up-, and down-votes|\n",
    "|source'| Name of retailer offering the sale|\n",
    "|'creation_date'| Date of initial post|\n",
    "|'last_reply'| Date of most recent reply|\n",
    "|'author'| User name of post author|\n",
    "|'replies'| Number of replies|\n",
    "|'views'| Number of views|\n",
    "|'price'| Price of product on sale|\n",
    "|'saving'| Associated saving|\n",
    "|'expiry'| Expiry date of sale|\n",
    "|'url'| Link to deal|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import requests # Scraping\n",
    "from bs4 import BeautifulSoup # HTML parsing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Retrieving data from the \"Hot Deals - All Categories\" sub-forum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Page format: `url/page#/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL base, current page, and total number of pages. Used to iterate over page URLs.\n",
    "current_page = \"\" # page number used to format base URL\n",
    "total_pages = 1 # total number for endpoint of iteration\n",
    "root_url = \"https://forums.redflagdeals.com/hot-deals-f9/\" # base url for \"Hot Deals\"\n",
    "\n",
    "# URL base to generate links to specific posts\n",
    "base_url = \"https://forums.redflagdeals.com\"\n",
    "\n",
    "# Dataframe to store scraped data\n",
    "# gloale keyword allows modification in function\n",
    "table = pd.DataFrame(columns=\n",
    "    ['title',\n",
    "    'votes',\n",
    "    'source',\n",
    "    'creation_date',\n",
    "    'last_reply',\n",
    "    'author',\n",
    "    'replies',\n",
    "    'views',\n",
    "    'price',\n",
    "    'saving',\n",
    "    'expiry',\n",
    "    'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts(page: str):\n",
    "    \"\"\"Returns list of all HTML post elements found on page and sets total_pages variable\"\"\"\n",
    "    \n",
    "    # Initalize list of posts on page class=\"row topic\"\n",
    "    posts = []\n",
    "    \n",
    "    # Get entire page content\n",
    "    response = requests.get(page)\n",
    "    content = response.content\n",
    "\n",
    "    # URL parser\n",
    "    parser = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # Find total number of pages\n",
    "    # Format of text: \" {current page #} of {total page #} \"\n",
    "    # Need to strip white space and extract total page #\n",
    "    pages = parser.select(\".pagination_menu_trigger\")[0].text.strip().split(\"of \")[1]\n",
    "    global total_pages\n",
    "    total_pages = int(pages) # Set global variable \n",
    "    \n",
    "    # Find and return list of topics\n",
    "    topics = parser.find_all(\"li\", class_=\"row topic\")\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_info(post: str) -> dict:\n",
    "    \"\"\"Extracts and returns additional information from a specific post:\n",
    "    url-link to the deal, the price, the discount percentage, the expiry date and \n",
    "    the parent/thread categories of the product. Returns NaN for objects that are not found.\"\"\"\n",
    "    \n",
    "    # Additional information about deal\n",
    "    add = {}\n",
    "    \n",
    "    # Get content of post\n",
    "    response = requests.get(post)\n",
    "    content = response.content\n",
    "    \n",
    "    # Parse URL\n",
    "    parser = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # Thread-header with information on parent and thread category\n",
    "    try: # parent category\n",
    "        parent_category = parser.select(\".thread_parent_category\")[0].text\n",
    "        add['Parent:'] = parent_category\n",
    "    except: add['Parent:'] = np.nan # NaN if category not found\n",
    "    try: # thread category\n",
    "        thread_category = parser.select(\".thread_category\")[0].text\n",
    "        add['Thread:'] = thread_category\n",
    "    except: add['Thread:'] = np.nan # NaN if category not found\n",
    "    \n",
    "    \n",
    "    # Offer-summary field: may contain deal link, price, saving, and retailer\n",
    "    summary = parser.select(\".post_offer_fields\") # format example: \"Price:\\n$200\\nSaving:\\n70%\"\n",
    "    try:\n",
    "        summary_list = summary[0].text.split(\"\\n\") \n",
    "    except: summary_list = []\n",
    "        \n",
    "    # Go through summary elements and save relevant information\n",
    "    for i in range(1, (len(summary_list) -1), 2): # index 0 is empty string\n",
    "        current_element = summary_list[i] # content of current list element\n",
    "        next_element = summary_list[i+1] # next list element\n",
    "        \n",
    "        # Price, saving, and expiry date information contained in the next list element will be saved\n",
    "        if current_element.startswith(\"Price\") or current_element.startswith(\"Saving\") or current_element.startswith(\"Expiry\"):\n",
    "            add[current_element]  = next_element # next elements corrsponds to content\n",
    "            \n",
    "    # URL to link. Full link not available through .text\n",
    "    try: \n",
    "        url = str(summary[0]).split('href=\"')[1].split('\"')[0] # select link between href=\" and \"\n",
    "        add['Link:'] = url\n",
    "    except: add['Link:'] = np.nan\n",
    "        \n",
    "    \n",
    "    # If any of the elements is not found in the summary-field add None value to dictionary \n",
    "    if \"Price:\" not in add:\n",
    "        add['Price:'] = np.nan\n",
    "        \n",
    "    if \"Savings:\" not in add:\n",
    "        add['Savings:'] = np.nan\n",
    "        \n",
    "    if \"Expiry:\" not in add:\n",
    "        add['Expiry:'] = np.nan\n",
    "    \n",
    "    return add # Return dictionary containing with information on price, saving and expiry  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_table(posts: list) -> None:\n",
    "    '''Fills table with data from elements of the post objects'''\n",
    "    \n",
    "    # For appending data \n",
    "    tmp_table = pd.DataFrame() # temporary DataFrame that holds all column objects. Will be appended to the global `table`. \n",
    "    \n",
    "    # Initializing columns for tmp_table\n",
    "    title_col = pd.Series()\n",
    "    source_col = pd.Series()\n",
    "    url_col = pd.Series()\n",
    "    votes_col = pd.Series()\n",
    "    replies_col = pd.Series()\n",
    "    views_col = pd.Series()\n",
    "    creation_date_col = pd.Series()\n",
    "    last_reply_col = pd.Series()\n",
    "    author_col = pd.Series()\n",
    "    price_col = pd.Series()\n",
    "    saving_col = pd.Series()\n",
    "    expiry_col = pd.Series()\n",
    "    parent_col = pd.Series()\n",
    "    thread_col = pd.Series()\n",
    "    \n",
    "\n",
    "    # Iterate through post elements and extract data for table\n",
    "    for post in posts:\n",
    "        \n",
    "        # Retailer corresponding to deal\n",
    "        try: \n",
    "            source = post.select(\".topictitle_retailer\")[0].text.split(\"\\n\")[0] # split and remove line-break characters\n",
    "            source_series = pd.Series(source) # transform into Series object\n",
    "        except: source_series = pd.Series(np.nan)\n",
    "        source_col = source_col.append(source_series, ignore_index=True) # append to column and ignore index to avoid complications when merging with DataFrame object\n",
    "\n",
    "        # Number of votes\n",
    "        try: \n",
    "            votes = post.select(\".post_voting\")[0].text.split(\"\\n\")[1] # split and remove line-break characters\n",
    "            votes_series = pd.Series(votes) # transform into Series object\n",
    "        except: votes_series = pd.Series(0)\n",
    "        votes_col = votes_col.append(votes_series, ignore_index=True) # append to column\n",
    "            \n",
    "        # Title \n",
    "        try:\n",
    "            topic = post.select(\".topic_title_link\") # contains title and sub-url to post\n",
    "            title = topic[0].text.split('\\n')[1] # extract text and remove line-break characters\n",
    "            title_series = pd.Series(title)\n",
    "        except: title_series = pd.Series(np.nan)\n",
    "        title_col = title_col.append(title_series, ignore_index=True)\n",
    "\n",
    "        # Date of initial posting\n",
    "        try: \n",
    "            creation = post.select(\".first-post-time\")[0].text.split(\"\\n\")[0] # remove line-breaks\n",
    "            creation_series = pd.Series(creation)\n",
    "        except: creation_series = pd.Series(np.nan)\n",
    "        creation_date_col = creation_date_col.append(creation_series, ignore_index=True) # append to column\n",
    "        \n",
    "        # Date of most recent replie\n",
    "        try: \n",
    "            last_replie = post.select(\".last-post-time\")[0].text.split(\"\\n\")[0] # remove line-breaks\n",
    "            last_replie_series = pd.Series(last_replie)\n",
    "        except: last_replie_series = pd.Series(np.nan)\n",
    "        last_reply_col = last_reply_col.append(last_replie_series, ignore_index=True) # append to column\n",
    "        \n",
    "        # Author user-name\n",
    "        try:\n",
    "            author = post.select(\".thread_meta_author\")[0].text.split(\"\\n\")[0]\n",
    "            author_series = pd.Series(author)\n",
    "        except: author_series = pd.Series(np.nan)\n",
    "        author_col = author_col.append(author_series, ignore_index=True)\n",
    "        \n",
    "        \n",
    "        # Number of replies\n",
    "        try:\n",
    "            replies = post.select(\".posts\")[0].text.split(\"\\n\")[0]\n",
    "            replies = replies.replace(\",\",\"\") # replace any commas to prepare for data type switch to integer\n",
    "            replies_series = pd.Series(replies)\n",
    "        except: replies_series = pd.Series(np.nan)\n",
    "        replies_col = replies_col.append(replies_series, ignore_index=True)\n",
    "        \n",
    "        # Number of views\n",
    "        try:\n",
    "            views = post.select(\".views\")[0].text.split(\"\\n\")[0]\n",
    "            views = views.replace(\",\",\"\") # replace any commas to prepare for data type switch to integer\n",
    "            views_series = pd.Series(views)\n",
    "        except: replies_series = pd.Series(np.nan)\n",
    "        views_col = views_col.append(views_series, ignore_index=True)\n",
    "        \n",
    "        # Link to current post\n",
    "        try:\n",
    "            link = str(topic).split('href=\"')[1] # split at href to extract link\n",
    "            link_clean = link.split('\">')[0] # remove superfluous characters\n",
    "        except: \n",
    "            link_clean = np.nan\n",
    "        \n",
    "        # Additional information post\n",
    "        if link_clean != None: # retrieve information from post, if it exists\n",
    "            post_url = (base_url + \"{}\").format(link_clean) # merge base-, and sub-url to generate the complete post-link\n",
    "            add_info = additional_info(post_url) # get additonal information on price, saving, and expiry-date\n",
    "            \n",
    "            # Fill columns with additional information from add_info dictionary\n",
    "            price_col = price_col.append(pd.Series(add_info['Price:']), ignore_index=True)\n",
    "            saving_col = saving_col.append(pd.Series(add_info['Savings:']), ignore_index=True)\n",
    "            expiry_col = expiry_col.append(pd.Series(add_info['Expiry:']), ignore_index=True)\n",
    "            url_col = url_col.append(pd.Series(add_info['Link:']), ignore_index=True)\n",
    "            parent_col = parent_col.append(pd.Series(add_info['Parent:']), ignore_index=True)\n",
    "            thread_col = thread_col.append(pd.Series(add_info['Thread:']), ignore_index=True)\n",
    "        else:\n",
    "            price_col = price_col.append(np.nan)\n",
    "            saving_col = saving_col.append(np.nan)\n",
    "            expiry_col = expiry_col.append(np.nan)\n",
    "            url_col = url_col.append(np.nan)\n",
    "        \n",
    "            \n",
    "    # Fill temporary table\n",
    "    tmp_table['title'] = title_col\n",
    "    tmp_table['votes'] = votes_col.astype(int)\n",
    "    tmp_table['source'] = source_col\n",
    "    tmp_table['creation_date'] = creation_date_col\n",
    "    tmp_table['last_reply'] = last_reply_col\n",
    "    tmp_table['author'] = author_col\n",
    "    tmp_table['replies'] = replies_col.astype(int)\n",
    "    tmp_table['views'] = views_col.astype(int)\n",
    "    tmp_table['price'] = price_col\n",
    "    tmp_table['saving'] = saving_col\n",
    "    tmp_table['expiry'] = expiry_col\n",
    "    tmp_table['url'] = url_col\n",
    "    tmp_table['parent_category'] = parent_col\n",
    "    tmp_table['thread_category'] = thread_col\n",
    "        \n",
    "    # Print result\n",
    "    global table # gloabal keyword allows modification inside function\n",
    "    table = table.append(tmp_table)\n",
    "    print(\"Current table length: \", table.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current table length:  30\n",
      "https://forums.redflagdeals.com/hot-deals-f9/2/\n",
      "Current table length:  60\n",
      "https://forums.redflagdeals.com/hot-deals-f9/3/\n",
      "Current table length:  90\n",
      "https://forums.redflagdeals.com/hot-deals-f9/4/\n",
      "Current table length:  120\n",
      "https://forums.redflagdeals.com/hot-deals-f9/5/\n",
      "Current table length:  150\n",
      "https://forums.redflagdeals.com/hot-deals-f9/6/\n",
      "Current table length:  179\n",
      "https://forums.redflagdeals.com/hot-deals-f9/7/\n",
      "Current table length:  209\n",
      "https://forums.redflagdeals.com/hot-deals-f9/8/\n",
      "Current table length:  239\n",
      "https://forums.redflagdeals.com/hot-deals-f9/9/\n",
      "Current table length:  269\n",
      "https://forums.redflagdeals.com/hot-deals-f9/10/\n",
      "Current table length:  299\n",
      "https://forums.redflagdeals.com/hot-deals-f9/11/\n",
      "Current table length:  329\n",
      "https://forums.redflagdeals.com/hot-deals-f9/12/\n",
      "Current table length:  359\n",
      "https://forums.redflagdeals.com/hot-deals-f9/13/\n",
      "Current table length:  389\n",
      "https://forums.redflagdeals.com/hot-deals-f9/14/\n",
      "Current table length:  419\n",
      "https://forums.redflagdeals.com/hot-deals-f9/15/\n",
      "Current table length:  449\n",
      "https://forums.redflagdeals.com/hot-deals-f9/16/\n",
      "Current table length:  479\n",
      "https://forums.redflagdeals.com/hot-deals-f9/17/\n",
      "Current table length:  509\n",
      "https://forums.redflagdeals.com/hot-deals-f9/18/\n",
      "Current table length:  539\n",
      "https://forums.redflagdeals.com/hot-deals-f9/19/\n",
      "Current table length:  569\n",
      "https://forums.redflagdeals.com/hot-deals-f9/20/\n",
      "Current table length:  599\n",
      "https://forums.redflagdeals.com/hot-deals-f9/21/\n",
      "Current table length:  629\n",
      "https://forums.redflagdeals.com/hot-deals-f9/22/\n",
      "Current table length:  659\n",
      "https://forums.redflagdeals.com/hot-deals-f9/23/\n",
      "Current table length:  689\n",
      "https://forums.redflagdeals.com/hot-deals-f9/24/\n",
      "Current table length:  719\n",
      "https://forums.redflagdeals.com/hot-deals-f9/25/\n",
      "Current table length:  749\n",
      "https://forums.redflagdeals.com/hot-deals-f9/26/\n",
      "Current table length:  779\n",
      "https://forums.redflagdeals.com/hot-deals-f9/27/\n",
      "Current table length:  809\n",
      "https://forums.redflagdeals.com/hot-deals-f9/28/\n",
      "Current table length:  839\n",
      "https://forums.redflagdeals.com/hot-deals-f9/29/\n",
      "Current table length:  869\n",
      "https://forums.redflagdeals.com/hot-deals-f9/30/\n",
      "Current table length:  899\n",
      "https://forums.redflagdeals.com/hot-deals-f9/31/\n",
      "Current table length:  929\n",
      "https://forums.redflagdeals.com/hot-deals-f9/32/\n",
      "Current table length:  959\n",
      "https://forums.redflagdeals.com/hot-deals-f9/33/\n",
      "Current table length:  989\n",
      "https://forums.redflagdeals.com/hot-deals-f9/34/\n",
      "Current table length:  1019\n",
      "https://forums.redflagdeals.com/hot-deals-f9/35/\n",
      "Current table length:  1049\n",
      "https://forums.redflagdeals.com/hot-deals-f9/36/\n",
      "Current table length:  1079\n",
      "https://forums.redflagdeals.com/hot-deals-f9/37/\n",
      "Current table length:  1109\n",
      "https://forums.redflagdeals.com/hot-deals-f9/38/\n",
      "Current table length:  1139\n",
      "https://forums.redflagdeals.com/hot-deals-f9/39/\n",
      "Current table length:  1169\n",
      "https://forums.redflagdeals.com/hot-deals-f9/40/\n",
      "Current table length:  1199\n",
      "https://forums.redflagdeals.com/hot-deals-f9/41/\n",
      "Current table length:  1229\n",
      "https://forums.redflagdeals.com/hot-deals-f9/42/\n",
      "Current table length:  1259\n",
      "https://forums.redflagdeals.com/hot-deals-f9/43/\n",
      "Current table length:  1289\n",
      "https://forums.redflagdeals.com/hot-deals-f9/44/\n",
      "Current table length:  1319\n",
      "https://forums.redflagdeals.com/hot-deals-f9/45/\n",
      "Current table length:  1349\n",
      "https://forums.redflagdeals.com/hot-deals-f9/46/\n",
      "Current table length:  1379\n",
      "https://forums.redflagdeals.com/hot-deals-f9/47/\n",
      "Current table length:  1409\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>expiry</th>\n",
       "      <th>last_reply</th>\n",
       "      <th>parent_category</th>\n",
       "      <th>price</th>\n",
       "      <th>replies</th>\n",
       "      <th>saving</th>\n",
       "      <th>source</th>\n",
       "      <th>thread_category</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pux420</td>\n",
       "      <td>Jun 29th, 2020 12:30 pm</td>\n",
       "      <td>July 12, 2020</td>\n",
       "      <td>Jul 12th, 2020 11:37 am</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "      <td>214.99</td>\n",
       "      <td>121</td>\n",
       "      <td>20%</td>\n",
       "      <td>Costco</td>\n",
       "      <td>Home Improvement &amp; Tools</td>\n",
       "      <td>Garage Epoxy $214.99</td>\n",
       "      <td>https://www.costco.ca/rokrez-epoxy-floor-coati...</td>\n",
       "      <td>35154</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Indubitably</td>\n",
       "      <td>Jul 12th, 2020 9:06 am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 12th, 2020 11:35 am</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>19.99</td>\n",
       "      <td>20</td>\n",
       "      <td>$23 off</td>\n",
       "      <td>Amazon.ca</td>\n",
       "      <td>Home Theatre &amp; Audio</td>\n",
       "      <td>Dudios True Wireless Earbuds - $19.99 with Prime</td>\n",
       "      <td>http://www.amazon.ca/gp/redirect.html?ie=UTF8&amp;...</td>\n",
       "      <td>2470</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>maverikbc</td>\n",
       "      <td>Jul 8th, 2020 9:31 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 12th, 2020 11:35 am</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Credit Cards</td>\n",
       "      <td>TD, BMO, and CIBC cash back 10% cards welcome ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15080</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>phoreoneone</td>\n",
       "      <td>Jun 30th, 2020 10:48 am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 12th, 2020 11:32 am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>Aeroplan with TD and Starbucks Offers YMMV CHE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AramisAtos</td>\n",
       "      <td>Jun 18th, 2020 3:20 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 12th, 2020 11:32 am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>70%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Levi's Warehouse Sale Event 70% off</td>\n",
       "      <td>http://levis-canada.sjv.io/c/341376/486184/846...</td>\n",
       "      <td>34354</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Mr2828</td>\n",
       "      <td>Jul 9th, 2020 5:42 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 12th, 2020 11:31 am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Foot Locker</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Ultraboost/NMD/Infinity React 50% + extra 15/2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48508</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>enzo85</td>\n",
       "      <td>Jul 12th, 2020 11:31 am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 12th, 2020 11:31 am</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>$499 - Miele Classic C1 Cat and Dog Canister V...</td>\n",
       "      <td>https://www.canadiantire.ca/en/pdp/miele-class...</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>SAN66</td>\n",
       "      <td>Jul 11th, 2020 4:09 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 12th, 2020 11:28 am</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>$129.97</td>\n",
       "      <td>22</td>\n",
       "      <td>30%</td>\n",
       "      <td>Staples</td>\n",
       "      <td>Peripherals &amp; Accessories</td>\n",
       "      <td>Google Home Wifi Router (1st gen) $129.97 in s...</td>\n",
       "      <td>https://staplescanada.4u8mqw.net/c/341376/7554...</td>\n",
       "      <td>4900</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>mangoman</td>\n",
       "      <td>Jul 10th, 2020 4:40 pm</td>\n",
       "      <td>July 12, 2020</td>\n",
       "      <td>Jul 12th, 2020 11:27 am</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>$499 + 20x</td>\n",
       "      <td>199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shoppers Drug Mart</td>\n",
       "      <td>Computers &amp; Tablets/eReaders</td>\n",
       "      <td>$499.99 Acer Aspire 3 Ryzen 3 3200U / 8GB RAM ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22448</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Blackdove77</td>\n",
       "      <td>Jul 6th, 2020 12:49 pm</td>\n",
       "      <td>July 12, 2020</td>\n",
       "      <td>Jul 12th, 2020 11:27 am</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111</td>\n",
       "      <td>100%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Video Games</td>\n",
       "      <td>Watchdogs 2 PC version free on July 12th</td>\n",
       "      <td>https://news.ubisoft.com/en-us/article/41nS5f7...</td>\n",
       "      <td>25379</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author            creation_date         expiry  \\\n",
       "0       pux420  Jun 29th, 2020 12:30 pm  July 12, 2020   \n",
       "1  Indubitably   Jul 12th, 2020 9:06 am            NaN   \n",
       "2    maverikbc    Jul 8th, 2020 9:31 pm            NaN   \n",
       "3  phoreoneone  Jun 30th, 2020 10:48 am            NaN   \n",
       "4   AramisAtos   Jun 18th, 2020 3:20 pm            NaN   \n",
       "5       Mr2828    Jul 9th, 2020 5:42 pm            NaN   \n",
       "6       enzo85  Jul 12th, 2020 11:31 am            NaN   \n",
       "7        SAN66   Jul 11th, 2020 4:09 pm            NaN   \n",
       "8     mangoman   Jul 10th, 2020 4:40 pm  July 12, 2020   \n",
       "9  Blackdove77   Jul 6th, 2020 12:49 pm  July 12, 2020   \n",
       "\n",
       "                last_reply          parent_category       price replies  \\\n",
       "0  Jul 12th, 2020 11:37 am            Home & Garden      214.99     121   \n",
       "1  Jul 12th, 2020 11:35 am  Computers & Electronics       19.99      20   \n",
       "2  Jul 12th, 2020 11:35 am       Financial Services         NaN      67   \n",
       "3  Jul 12th, 2020 11:32 am                      NaN         NaN       5   \n",
       "4  Jul 12th, 2020 11:32 am                      NaN         NaN      96   \n",
       "5  Jul 12th, 2020 11:31 am                      NaN         NaN     171   \n",
       "6  Jul 12th, 2020 11:31 am            Home & Garden         NaN       0   \n",
       "7  Jul 12th, 2020 11:28 am  Computers & Electronics     $129.97      22   \n",
       "8  Jul 12th, 2020 11:27 am  Computers & Electronics  $499 + 20x     199   \n",
       "9  Jul 12th, 2020 11:27 am  Computers & Electronics         NaN     111   \n",
       "\n",
       "    saving              source               thread_category  \\\n",
       "0      20%              Costco      Home Improvement & Tools   \n",
       "1  $23 off           Amazon.ca          Home Theatre & Audio   \n",
       "2      NaN                 NaN                  Credit Cards   \n",
       "3      NaN           Starbucks                     Groceries   \n",
       "4      70%                 NaN                       Apparel   \n",
       "5      NaN         Foot Locker                       Apparel   \n",
       "6      NaN                 NaN                    Appliances   \n",
       "7      30%             Staples     Peripherals & Accessories   \n",
       "8      NaN  Shoppers Drug Mart  Computers & Tablets/eReaders   \n",
       "9     100%                 NaN                   Video Games   \n",
       "\n",
       "                                               title  \\\n",
       "0                               Garage Epoxy $214.99   \n",
       "1   Dudios True Wireless Earbuds - $19.99 with Prime   \n",
       "2  TD, BMO, and CIBC cash back 10% cards welcome ...   \n",
       "3  Aeroplan with TD and Starbucks Offers YMMV CHE...   \n",
       "4                Levi's Warehouse Sale Event 70% off   \n",
       "5  Ultraboost/NMD/Infinity React 50% + extra 15/2...   \n",
       "6  $499 - Miele Classic C1 Cat and Dog Canister V...   \n",
       "7  Google Home Wifi Router (1st gen) $129.97 in s...   \n",
       "8  $499.99 Acer Aspire 3 Ryzen 3 3200U / 8GB RAM ...   \n",
       "9           Watchdogs 2 PC version free on July 12th   \n",
       "\n",
       "                                                 url  views votes  \n",
       "0  https://www.costco.ca/rokrez-epoxy-floor-coati...  35154    22  \n",
       "1  http://www.amazon.ca/gp/redirect.html?ie=UTF8&...   2470    19  \n",
       "2                                                NaN  15080    19  \n",
       "3                                                NaN   1440     0  \n",
       "4  http://levis-canada.sjv.io/c/341376/486184/846...  34354    59  \n",
       "5                                                NaN  48508   112  \n",
       "6  https://www.canadiantire.ca/en/pdp/miele-class...     66     0  \n",
       "7  https://staplescanada.4u8mqw.net/c/341376/7554...   4900     4  \n",
       "8                                                NaN  22448    21  \n",
       "9  https://news.ubisoft.com/en-us/article/41nS5f7...  25379   105  "
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First page information, and set total_pages through get_posts()\n",
    "# Generate list of posts on first page\n",
    "posts = get_posts(url)  \n",
    "# Fill table from information on first page and corresponding posts\n",
    "fill_table(posts)\n",
    "\n",
    "#Loop through pages and fill table\n",
    "for page in range(2, total_pages):\n",
    "    next_url = root_url + str(page) + \"/\" # URL of next page: base-url + number + \"/\"\n",
    "    print(next_url)\n",
    "    # Generate list of posts on current page\n",
    "    posts = get_posts(next_url)\n",
    "\n",
    "    # Fill table from information on current page and posts\n",
    "    fill_table(posts)\n",
    "\n",
    "# Print first 10 rows\n",
    "table.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data to csv file\n",
    "table.to_csv('C:/Users/User/Documents/GitHub/Data-Science/rfd_scrape.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1409 entries, 0 to 1408\n",
      "Data columns (total 15 columns):\n",
      "Unnamed: 0         1409 non-null int64\n",
      "author             1409 non-null object\n",
      "creation_date      1409 non-null object\n",
      "expiry             419 non-null object\n",
      "last_reply         1409 non-null object\n",
      "parent_category    869 non-null object\n",
      "price              960 non-null object\n",
      "replies            1409 non-null int64\n",
      "saving             561 non-null object\n",
      "source             1058 non-null object\n",
      "thread_category    1409 non-null object\n",
      "title              1409 non-null object\n",
      "url                1103 non-null object\n",
      "views              1409 non-null int64\n",
      "votes              1409 non-null int64\n",
      "dtypes: int64(4), object(11)\n",
      "memory usage: 165.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('rfd_scrape.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
