{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[RedFlagDeals](https://forums.redflagdeals.com/hot-deals-f9/) is a forum where users can post sales or deals that they have come accross. The first part of this project is focused on scraping relevant information from the \"All Hot Deals\" section that includes all product categories. In the second and third part I will clean and visualize the data to extract and summarize useful information.  \n",
    "\n",
    "|Column name|Description|\n",
    "|---|---|\n",
    "|'title'| Title of post|\n",
    "|'votes'| Sum of up-, and down-votes|\n",
    "|'source'| Name of retailer offering the sale|\n",
    "|'creation_date'| Date of initial post|\n",
    "|'last_reply'| Date of most recent reply|\n",
    "|'author'| User name of post author|\n",
    "|'replies'| Number of replies|\n",
    "|'views'| Number of views|\n",
    "|'price'| Price of product on sale|\n",
    "|'saving'| Associated saving|\n",
    "|'expiry'| Expiry date of sale|\n",
    "|'url'| Link to deal|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import requests # Scraping\n",
    "from bs4 import BeautifulSoup # HTML parsing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Retrieving data from the \"All Hot Deals\" sub-forum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL format for different pages: `root-url/page#/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize global variables used to iterate over web-pages.\n",
    "current_page = \"\" # page number; used to format root URL\n",
    "total_pages = 1 # endpoint for iteration; set through get_posts()\n",
    "root_url = \"https://forums.redflagdeals.com/hot-deals-f9/\" # base url for \"All Hot Deals\" sub-forum\n",
    "\n",
    "# URL base to generate links to specific posts\n",
    "base_url = \"https://forums.redflagdeals.com\"\n",
    "\n",
    "# Dataframe to store scraped data\n",
    "table = pd.DataFrame(columns=\n",
    "    ['title',\n",
    "    'votes',\n",
    "    'source',\n",
    "    'creation_date',\n",
    "    'last_reply',\n",
    "    'author',\n",
    "    'replies',\n",
    "    'views',\n",
    "    'price',\n",
    "    'saving',\n",
    "    'expiry',\n",
    "    'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts(page: str) -> list:\n",
    "    \"\"\"\n",
    "    Returns list of parsed object containing all post elements from\n",
    "    the current 'page' and sets gloabl variable 'total_pages'\n",
    "    \n",
    "    Args:\n",
    "    page - url string of current page\n",
    "    \n",
    "    Returns:\n",
    "    topics - all parsed elements of class 'row topic'\n",
    "    total_pages - sets global variable\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initalize list of posts on page class=\"row topic\"\n",
    "    posts = []\n",
    "    \n",
    "    # Get entire page content\n",
    "    response = requests.get(page)\n",
    "    content = response.content\n",
    "    \n",
    "    # Find total number of pages and set global variable accordingly\n",
    "    # Format of text: \" {current page #} of {total page #} \"\n",
    "    # Need to strip white space and extract total page #\n",
    "    parser = BeautifulSoup(content, 'html.parser')\n",
    "    pages = parser.select(\".pagination_menu_trigger\")[0].text.strip().split(\"of \")[1]\n",
    "    global total_pages\n",
    "    total_pages = int(pages)\n",
    "    \n",
    "    # Find and return topics\n",
    "    topics = parser.find_all(\"li\", class_=\"row topic\")\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_additional_info(post: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts and returns additional information from a RedFlagDeal post:\n",
    "    url-link to the deal, the price of the product, the discount saving, \n",
    "    the expiry date and the parent/thread categories of the product. Returns \n",
    "    NaN values for objects that are not found.\n",
    "    \n",
    "    Args:\n",
    "    post - url string linking to a specific post\n",
    "    \n",
    "    Returns:\n",
    "    additional_info - dictionary containing additional information about the post.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Additional information found in post\n",
    "    additional_info = {}\n",
    "    \n",
    "    # Get content of post\n",
    "    response = requests.get(post)\n",
    "    content = response.content\n",
    "    parser = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # Thread-header with information on parent and thread category\n",
    "    try: # parent category\n",
    "        parent_category = parser.select(\".thread_parent_category\")[0].text\n",
    "        additional_info['Parent:'] = parent_category\n",
    "    except: additional_info['Parent:'] = np.nan # NaN if category not found\n",
    "    try: # thread category\n",
    "        thread_category = parser.select(\".thread_category\")[0].text\n",
    "        additional_info['Thread:'] = thread_category\n",
    "    except: additional_info['Thread:'] = np.nan # NaN if category not found\n",
    "    \n",
    "    \n",
    "    # Offer-summary field: may contain deal link, price, saving, and retailer\n",
    "    summary = parser.select(\".post_offer_fields\") # format example: \"Price:\\n$200\\nSaving:\\n70%\"\n",
    "    try:\n",
    "        summary_list = summary[0].text.split(\"\\n\") \n",
    "    except: summary_list = []\n",
    "        \n",
    "    # Go through summary elements and save relevant information\n",
    "    for i in range(1, (len(summary_list) -1), 2): # index 0 is empty string\n",
    "        current_element = summary_list[i] # content of current list element\n",
    "        next_element = summary_list[i+1] # next list element\n",
    "        \n",
    "        # Price, saving, and expiry date information contained in the next list element will be saved\n",
    "        if current_element.startswith(\"Price\") or current_element.startswith(\"Saving\") or current_element.startswith(\"Expiry\"):\n",
    "            additional_info[current_element]  = next_element # next elements corrsponds to content\n",
    "            \n",
    "    # URL to link. Full link not available through .text\n",
    "    try: \n",
    "        url = str(summary[0]).split('href=\"')[1].split('\"')[0] # select link between href=\" and \"\n",
    "        additional_info['Link:'] = url\n",
    "    except: additional_info['Link:'] = np.nan\n",
    "        \n",
    "    \n",
    "    # If any of the elements is not found in the summary-field add None value to dictionary \n",
    "    if \"Price:\" not in additional_info:\n",
    "        additional_info['Price:'] = np.nan\n",
    "        \n",
    "    if \"Savings:\" not in additional_info:\n",
    "        additional_info['Savings:'] = np.nan\n",
    "        \n",
    "    if \"Expiry:\" not in additional_info:\n",
    "        additional_info['Expiry:'] = np.nan\n",
    "    \n",
    "    return additional_info # Return dictionary containing with information on price, saving and expiry  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_table(posts: list) -> None:\n",
    "    '''\n",
    "    Extracts parsed data from current page and appends to the global table variable.\n",
    "    \n",
    "    Args:\n",
    "    posts - list of parsed post elements obtained through get_posts()\n",
    "    '''\n",
    "    \n",
    "    # Temporary DataFrame object that will be appended to the global 'table' variable\n",
    "    tmp_table = pd.DataFrame() \n",
    "    \n",
    "    # Initializing columns for tmp_table\n",
    "    title_col = pd.Series()\n",
    "    source_col = pd.Series()\n",
    "    url_col = pd.Series()\n",
    "    votes_col = pd.Series()\n",
    "    replies_col = pd.Series()\n",
    "    views_col = pd.Series()\n",
    "    creation_date_col = pd.Series()\n",
    "    last_reply_col = pd.Series()\n",
    "    author_col = pd.Series()\n",
    "    price_col = pd.Series()\n",
    "    saving_col = pd.Series()\n",
    "    expiry_col = pd.Series()\n",
    "    parent_col = pd.Series()\n",
    "    thread_col = pd.Series()\n",
    "    \n",
    "\n",
    "    # Iterate through post elements on current page and extract data for table\n",
    "    for post in posts:\n",
    "        \n",
    "        # Retailer corresponding to deal\n",
    "        try: \n",
    "            source = post.select(\".topictitle_retailer\")[0].text.split(\"\\n\")[0] # split and remove line-break characters\n",
    "            source_series = pd.Series(source) # transforming into Series object allows use of .append method\n",
    "        except: source_series = pd.Series(np.nan)\n",
    "        source_col = source_col.append(source_series, ignore_index=True)\n",
    "\n",
    "        # Number of votes\n",
    "        try: \n",
    "            votes = post.select(\".post_voting\")[0].text.split(\"\\n\")[1] \n",
    "            votes_series = pd.Series(votes) \n",
    "        except: votes_series = pd.Series(0)\n",
    "        votes_col = votes_col.append(votes_series, ignore_index=True)\n",
    "            \n",
    "        # Title \n",
    "        try:\n",
    "            topic = post.select(\".topic_title_link\") \n",
    "            title = topic[0].text.split('\\n')[1] \n",
    "            title_series = pd.Series(title)\n",
    "        except: title_series = pd.Series(np.nan)\n",
    "        title_col = title_col.append(title_series, ignore_index=True)\n",
    "\n",
    "        # Date of initial posting\n",
    "        try: \n",
    "            creation = post.select(\".first-post-time\")[0].text.split(\"\\n\")[0]\n",
    "            creation_series = pd.Series(creation)\n",
    "        except: creation_series = pd.Series(np.nan)\n",
    "        creation_date_col = creation_date_col.append(creation_series, ignore_index=True) \n",
    "        \n",
    "        # Date of most recent replie\n",
    "        try: \n",
    "            last_replie = post.select(\".last-post-time\")[0].text.split(\"\\n\")[0]\n",
    "            last_replie_series = pd.Series(last_replie)\n",
    "        except: last_replie_series = pd.Series(np.nan)\n",
    "        last_reply_col = last_reply_col.append(last_replie_series, ignore_index=True) \n",
    "        \n",
    "        # Author user-name\n",
    "        try:\n",
    "            author = post.select(\".thread_meta_author\")[0].text.split(\"\\n\")[0]\n",
    "            author_series = pd.Series(author)\n",
    "        except: author_series = pd.Series(np.nan)\n",
    "        author_col = author_col.append(author_series, ignore_index=True)\n",
    "        \n",
    "        \n",
    "        # Number of replies\n",
    "        try:\n",
    "            replies = post.select(\".posts\")[0].text.split(\"\\n\")[0]\n",
    "            replies = replies.replace(\",\",\"\") # remove commas to facilitate data type conversion to integer\n",
    "            replies_series = pd.Series(replies)\n",
    "        except: replies_series = pd.Series(np.nan)\n",
    "        replies_col = replies_col.append(replies_series, ignore_index=True)\n",
    "        \n",
    "        # Number of views\n",
    "        try:\n",
    "            views = post.select(\".views\")[0].text.split(\"\\n\")[0]\n",
    "            views = views.replace(\",\",\"\") # remove commas to facilitate integer conversion\n",
    "            views_series = pd.Series(views)\n",
    "        except: replies_series = pd.Series(np.nan)\n",
    "        views_col = views_col.append(views_series, ignore_index=True)\n",
    "        \n",
    "        # Link to current post\n",
    "        try:\n",
    "            link = str(topic).split('href=\"')[1] # split at href to extract link\n",
    "            link_clean = link.split('\">')[0] # remove superfluous characters\n",
    "        except: \n",
    "            link_clean = np.nan\n",
    "        \n",
    "        # Additional information post\n",
    "        if link_clean != None: # retrieve information from post, if url exists\n",
    "            complete_url = (base_url + \"{}\").format(link_clean) # merge base-, and sub-url to generate the complete post-link\n",
    "            additional_info = get_additional_info(complete_url) # get dictionary of additonal information on price, saving, etc.\n",
    "            \n",
    "            # Fill columns with additional information from additional_info dictionary\n",
    "            price_col = price_col.append(pd.Series(additional_info['Price:']), ignore_index=True)\n",
    "            saving_col = saving_col.append(pd.Series(additional_info['Savings:']), ignore_index=True)\n",
    "            expiry_col = expiry_col.append(pd.Series(additional_info['Expiry:']), ignore_index=True)\n",
    "            url_col = url_col.append(pd.Series(additional_info['Link:']), ignore_index=True)\n",
    "            parent_col = parent_col.append(pd.Series(additional_info['Parent:']), ignore_index=True)\n",
    "            thread_col = thread_col.append(pd.Series(additional_info['Thread:']), ignore_index=True)\n",
    "        else:\n",
    "            price_col = price_col.append(np.nan)\n",
    "            saving_col = saving_col.append(np.nan)\n",
    "            expiry_col = expiry_col.append(np.nan)\n",
    "            url_col = url_col.append(np.nan)\n",
    "        \n",
    "            \n",
    "    # Fill temporary table\n",
    "    tmp_table['title'] = title_col\n",
    "    tmp_table['votes'] = votes_col.astype(int)\n",
    "    tmp_table['source'] = source_col\n",
    "    tmp_table['creation_date'] = creation_date_col\n",
    "    tmp_table['last_reply'] = last_reply_col\n",
    "    tmp_table['author'] = author_col\n",
    "    tmp_table['replies'] = replies_col.astype(int)\n",
    "    tmp_table['views'] = views_col.astype(int)\n",
    "    tmp_table['price'] = price_col\n",
    "    tmp_table['saving'] = saving_col\n",
    "    tmp_table['expiry'] = expiry_col\n",
    "    tmp_table['url'] = url_col\n",
    "    tmp_table['parent_category'] = parent_col\n",
    "    tmp_table['thread_category'] = thread_col\n",
    "        \n",
    "    # Print result\n",
    "    global table # gloabal keyword allows modification inside function\n",
    "    table = table.append(tmp_table)\n",
    "    print(\"Current table length: \", table.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting information from page: 1\n",
      "Current table length:  30\n",
      "Extracting information from page:  2  of  51\n",
      "Current table length:  60\n",
      "Extracting information from page:  3  of  51\n",
      "Current table length:  90\n",
      "Extracting information from page:  4  of  51\n",
      "Current table length:  120\n",
      "Extracting information from page:  5  of  51\n",
      "Current table length:  150\n",
      "Extracting information from page:  6  of  51\n",
      "Current table length:  180\n",
      "Extracting information from page:  7  of  51\n",
      "Current table length:  210\n",
      "Extracting information from page:  8  of  51\n",
      "Current table length:  240\n",
      "Extracting information from page:  9  of  51\n",
      "Current table length:  270\n",
      "Extracting information from page:  10  of  51\n",
      "Current table length:  300\n",
      "Extracting information from page:  11  of  51\n",
      "Current table length:  330\n",
      "Extracting information from page:  12  of  51\n",
      "Current table length:  360\n",
      "Extracting information from page:  13  of  51\n",
      "Current table length:  390\n",
      "Extracting information from page:  14  of  51\n",
      "Current table length:  420\n",
      "Extracting information from page:  15  of  51\n",
      "Current table length:  450\n",
      "Extracting information from page:  16  of  51\n",
      "Current table length:  480\n",
      "Extracting information from page:  17  of  51\n",
      "Current table length:  510\n",
      "Extracting information from page:  18  of  51\n",
      "Current table length:  540\n",
      "Extracting information from page:  19  of  51\n",
      "Current table length:  570\n",
      "Extracting information from page:  20  of  51\n",
      "Current table length:  600\n",
      "Extracting information from page:  21  of  51\n",
      "Current table length:  630\n",
      "Extracting information from page:  22  of  51\n",
      "Current table length:  660\n",
      "Extracting information from page:  23  of  51\n",
      "Current table length:  690\n",
      "Extracting information from page:  24  of  51\n",
      "Current table length:  720\n",
      "Extracting information from page:  25  of  51\n",
      "Current table length:  750\n",
      "Extracting information from page:  26  of  51\n",
      "Current table length:  780\n",
      "Extracting information from page:  27  of  51\n",
      "Current table length:  810\n",
      "Extracting information from page:  28  of  51\n",
      "Current table length:  840\n",
      "Extracting information from page:  29  of  51\n",
      "Current table length:  870\n",
      "Extracting information from page:  30  of  51\n",
      "Current table length:  900\n",
      "Extracting information from page:  31  of  51\n",
      "Current table length:  930\n",
      "Extracting information from page:  32  of  51\n",
      "Current table length:  960\n",
      "Extracting information from page:  33  of  51\n",
      "Current table length:  990\n",
      "Extracting information from page:  34  of  51\n",
      "Current table length:  1020\n",
      "Extracting information from page:  35  of  51\n",
      "Current table length:  1050\n",
      "Extracting information from page:  36  of  51\n",
      "Current table length:  1080\n",
      "Extracting information from page:  37  of  51\n",
      "Current table length:  1110\n",
      "Extracting information from page:  38  of  51\n",
      "Current table length:  1140\n",
      "Extracting information from page:  39  of  51\n",
      "Current table length:  1170\n",
      "Extracting information from page:  40  of  51\n",
      "Current table length:  1200\n",
      "Extracting information from page:  41  of  51\n",
      "Current table length:  1230\n",
      "Extracting information from page:  42  of  51\n",
      "Current table length:  1260\n",
      "Extracting information from page:  43  of  51\n",
      "Current table length:  1290\n",
      "Extracting information from page:  44  of  51\n",
      "Current table length:  1320\n",
      "Extracting information from page:  45  of  51\n",
      "Current table length:  1350\n",
      "Extracting information from page:  46  of  51\n",
      "Current table length:  1380\n",
      "Extracting information from page:  47  of  51\n",
      "Current table length:  1410\n",
      "Extracting information from page:  48  of  51\n",
      "Current table length:  1440\n",
      "Extracting information from page:  49  of  51\n",
      "Current table length:  1470\n",
      "Extracting information from page:  50  of  51\n",
      "Current table length:  1500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>expiry</th>\n",
       "      <th>last_reply</th>\n",
       "      <th>parent_category</th>\n",
       "      <th>price</th>\n",
       "      <th>replies</th>\n",
       "      <th>saving</th>\n",
       "      <th>source</th>\n",
       "      <th>thread_category</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>trystee</td>\n",
       "      <td>Jan 1st, 2020 8:32 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 13th, 2020 3:25 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>[Various Retailers] Gift Card Deals And Discou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365169</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>yellowmp5</td>\n",
       "      <td>Jul 13th, 2020 1:29 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 13th, 2020 3:23 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "      <td>RYOBI 20% coupon barcode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2593</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>phoreoneone</td>\n",
       "      <td>Jul 13th, 2020 12:34 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 13th, 2020 3:23 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dell</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>Dell G5 - 15\" 144Hz, i7-10750H, 16GB, 512GB, R...</td>\n",
       "      <td>http://www.jdoqocy.com/click-749547-12105225?u...</td>\n",
       "      <td>2339</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Blackdove77</td>\n",
       "      <td>Jul 6th, 2020 12:49 pm</td>\n",
       "      <td>July 19, 2020</td>\n",
       "      <td>Jul 13th, 2020 3:23 pm</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413</td>\n",
       "      <td>100%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Video Games</td>\n",
       "      <td>Watchdogs 2 PC version free for Everyone</td>\n",
       "      <td>https://register.ubisoft.com/ubisoft-forward-r...</td>\n",
       "      <td>57748</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>hkhorace</td>\n",
       "      <td>Jul 6th, 2020 9:56 am</td>\n",
       "      <td>July 12, 2020</td>\n",
       "      <td>Jul 13th, 2020 3:22 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1300</td>\n",
       "      <td>77</td>\n",
       "      <td>$200 off</td>\n",
       "      <td>Costco</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Quickjack 7000slx $200 off - $1300</td>\n",
       "      <td>https://www.costco.ca/quickjack-bl-7000slx-318...</td>\n",
       "      <td>15093</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>jugojugo</td>\n",
       "      <td>Jul 8th, 2020 9:26 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 13th, 2020 3:22 pm</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>Home Improvement &amp; Tools</td>\n",
       "      <td>RYOBI 2020 Summer Tour - 20% off 18V + 40V too...</td>\n",
       "      <td>https://bit.ly/RYOBISummerTour</td>\n",
       "      <td>16592</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>idiotcanuck</td>\n",
       "      <td>Jul 13th, 2020 12:06 pm</td>\n",
       "      <td>July 14, 2020</td>\n",
       "      <td>Jul 13th, 2020 3:22 pm</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>517.99</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Costco</td>\n",
       "      <td>Televisions</td>\n",
       "      <td>Hisense 55-in. 4K ULED Android Smart TV 55Q7G ...</td>\n",
       "      <td>https://www.costco.ca/hisense-55-in.-4k-uled-a...</td>\n",
       "      <td>1562</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>kooltilltheen</td>\n",
       "      <td>Jul 7th, 2020 4:12 am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 13th, 2020 3:22 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Upto 75% Off On Everything On Old Navy/Gap + E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19157</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>tmd2006</td>\n",
       "      <td>Jul 13th, 2020 11:49 am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 13th, 2020 3:21 pm</td>\n",
       "      <td>Kids &amp; Babies</td>\n",
       "      <td>199</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Costco</td>\n",
       "      <td>Toys &amp; Games</td>\n",
       "      <td>Costco.ca Geometric dome climbing structure $199</td>\n",
       "      <td>https://www.costco.ca/lifetime-geometric-dome-...</td>\n",
       "      <td>2499</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>fangdragon2000</td>\n",
       "      <td>Jul 9th, 2020 11:51 am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 13th, 2020 3:20 pm</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>139,99</td>\n",
       "      <td>65</td>\n",
       "      <td>30$</td>\n",
       "      <td>Amazon.ca</td>\n",
       "      <td>Peripherals &amp; Accessories</td>\n",
       "      <td>ADATA USA Ultimate Su800 1TB 3D Nand 2.5 Inch ...</td>\n",
       "      <td>http://www.amazon.ca/gp/redirect.html?ie=UTF8&amp;...</td>\n",
       "      <td>8986</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author            creation_date         expiry  \\\n",
       "0         trystee    Jan 1st, 2020 8:32 pm            NaN   \n",
       "1       yellowmp5   Jul 13th, 2020 1:29 pm            NaN   \n",
       "2     phoreoneone  Jul 13th, 2020 12:34 pm            NaN   \n",
       "3     Blackdove77   Jul 6th, 2020 12:49 pm  July 19, 2020   \n",
       "4        hkhorace    Jul 6th, 2020 9:56 am  July 12, 2020   \n",
       "5        jugojugo    Jul 8th, 2020 9:26 pm            NaN   \n",
       "6     idiotcanuck  Jul 13th, 2020 12:06 pm  July 14, 2020   \n",
       "7   kooltilltheen    Jul 7th, 2020 4:12 am            NaN   \n",
       "8         tmd2006  Jul 13th, 2020 11:49 am            NaN   \n",
       "9  fangdragon2000   Jul 9th, 2020 11:51 am            NaN   \n",
       "\n",
       "               last_reply          parent_category   price replies    saving  \\\n",
       "0  Jul 13th, 2020 3:25 pm                      NaN     NaN     672       NaN   \n",
       "1  Jul 13th, 2020 3:23 pm                      NaN     NaN      26       NaN   \n",
       "2  Jul 13th, 2020 3:23 pm                      NaN     NaN      23       NaN   \n",
       "3  Jul 13th, 2020 3:23 pm  Computers & Electronics     NaN     413      100%   \n",
       "4  Jul 13th, 2020 3:22 pm                      NaN    1300      77  $200 off   \n",
       "5  Jul 13th, 2020 3:22 pm            Home & Garden     NaN      87       NaN   \n",
       "6  Jul 13th, 2020 3:22 pm  Computers & Electronics  517.99      20       NaN   \n",
       "7  Jul 13th, 2020 3:22 pm                      NaN     NaN      51       NaN   \n",
       "8  Jul 13th, 2020 3:21 pm            Kids & Babies     199       7       NaN   \n",
       "9  Jul 13th, 2020 3:20 pm  Computers & Electronics  139,99      65       30$   \n",
       "\n",
       "       source            thread_category  \\\n",
       "0         NaN                  Groceries   \n",
       "1  Home Depot              Home & Garden   \n",
       "2        Dell    Computers & Electronics   \n",
       "3         NaN                Video Games   \n",
       "4      Costco                 Automotive   \n",
       "5  Home Depot   Home Improvement & Tools   \n",
       "6      Costco                Televisions   \n",
       "7         NaN                    Apparel   \n",
       "8      Costco               Toys & Games   \n",
       "9   Amazon.ca  Peripherals & Accessories   \n",
       "\n",
       "                                               title  \\\n",
       "0  [Various Retailers] Gift Card Deals And Discou...   \n",
       "1                           RYOBI 20% coupon barcode   \n",
       "2  Dell G5 - 15\" 144Hz, i7-10750H, 16GB, 512GB, R...   \n",
       "3           Watchdogs 2 PC version free for Everyone   \n",
       "4                 Quickjack 7000slx $200 off - $1300   \n",
       "5  RYOBI 2020 Summer Tour - 20% off 18V + 40V too...   \n",
       "6  Hisense 55-in. 4K ULED Android Smart TV 55Q7G ...   \n",
       "7  Upto 75% Off On Everything On Old Navy/Gap + E...   \n",
       "8   Costco.ca Geometric dome climbing structure $199   \n",
       "9  ADATA USA Ultimate Su800 1TB 3D Nand 2.5 Inch ...   \n",
       "\n",
       "                                                 url   views votes  \n",
       "0                                                NaN  365169   317  \n",
       "1                                                NaN    2593    28  \n",
       "2  http://www.jdoqocy.com/click-749547-12105225?u...    2339    15  \n",
       "3  https://register.ubisoft.com/ubisoft-forward-r...   57748   180  \n",
       "4  https://www.costco.ca/quickjack-bl-7000slx-318...   15093    26  \n",
       "5                     https://bit.ly/RYOBISummerTour   16592    28  \n",
       "6  https://www.costco.ca/hisense-55-in.-4k-uled-a...    1562     4  \n",
       "7                                                NaN   19157    16  \n",
       "8  https://www.costco.ca/lifetime-geometric-dome-...    2499     3  \n",
       "9  http://www.amazon.ca/gp/redirect.html?ie=UTF8&...    8986     3  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get first page information, and set total_pages through get_posts()\n",
    "print('Extracting information from page: 1')\n",
    "posts = get_posts(root_url)  \n",
    "# Extract infomation from first page to fill table with data\n",
    "fill_table(posts)\n",
    "\n",
    "#Loop through pages and add data to table\n",
    "for page in range(2, (total_pages + 1):\n",
    "    next_url = root_url + str(page) + \"/\" # URL of next page: base-url + number + \"/\"\n",
    "    print('Extracting information from page: ', page, \" of \", total_pages)\n",
    "    # Generate list of posts on current page\n",
    "    posts = get_posts(next_url)\n",
    "\n",
    "    # Fill table from information on current page and posts\n",
    "    fill_table(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data to csv file\n",
    "table.to_csv('C:/Users/User/Documents/GitHub/Data-Science/rfd_scrape.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>expiry</th>\n",
       "      <th>last_reply</th>\n",
       "      <th>parent_category</th>\n",
       "      <th>price</th>\n",
       "      <th>replies</th>\n",
       "      <th>saving</th>\n",
       "      <th>source</th>\n",
       "      <th>thread_category</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>trystee</td>\n",
       "      <td>Jan 1st, 2020 8:32 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 13th, 2020 3:25 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>[Various Retailers] Gift Card Deals And Discou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365169</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>yellowmp5</td>\n",
       "      <td>Jul 13th, 2020 1:29 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 13th, 2020 3:23 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "      <td>RYOBI 20% coupon barcode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2593</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>phoreoneone</td>\n",
       "      <td>Jul 13th, 2020 12:34 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 13th, 2020 3:23 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dell</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>Dell G5 - 15\" 144Hz, i7-10750H, 16GB, 512GB, R...</td>\n",
       "      <td>http://www.jdoqocy.com/click-749547-12105225?u...</td>\n",
       "      <td>2339</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Blackdove77</td>\n",
       "      <td>Jul 6th, 2020 12:49 pm</td>\n",
       "      <td>July 19, 2020</td>\n",
       "      <td>Jul 13th, 2020 3:23 pm</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413</td>\n",
       "      <td>100%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Video Games</td>\n",
       "      <td>Watchdogs 2 PC version free for Everyone</td>\n",
       "      <td>https://register.ubisoft.com/ubisoft-forward-r...</td>\n",
       "      <td>57748</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>hkhorace</td>\n",
       "      <td>Jul 6th, 2020 9:56 am</td>\n",
       "      <td>July 12, 2020</td>\n",
       "      <td>Jul 13th, 2020 3:22 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1300</td>\n",
       "      <td>77</td>\n",
       "      <td>$200 off</td>\n",
       "      <td>Costco</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Quickjack 7000slx $200 off - $1300</td>\n",
       "      <td>https://www.costco.ca/quickjack-bl-7000slx-318...</td>\n",
       "      <td>15093</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author            creation_date         expiry  \\\n",
       "0      trystee    Jan 1st, 2020 8:32 pm            NaN   \n",
       "1    yellowmp5   Jul 13th, 2020 1:29 pm            NaN   \n",
       "2  phoreoneone  Jul 13th, 2020 12:34 pm            NaN   \n",
       "3  Blackdove77   Jul 6th, 2020 12:49 pm  July 19, 2020   \n",
       "4     hkhorace    Jul 6th, 2020 9:56 am  July 12, 2020   \n",
       "\n",
       "               last_reply          parent_category price  replies    saving  \\\n",
       "0  Jul 13th, 2020 3:25 pm                      NaN   NaN      672       NaN   \n",
       "1  Jul 13th, 2020 3:23 pm                      NaN   NaN       26       NaN   \n",
       "2  Jul 13th, 2020 3:23 pm                      NaN   NaN       23       NaN   \n",
       "3  Jul 13th, 2020 3:23 pm  Computers & Electronics   NaN      413      100%   \n",
       "4  Jul 13th, 2020 3:22 pm                      NaN  1300       77  $200 off   \n",
       "\n",
       "       source          thread_category  \\\n",
       "0         NaN                Groceries   \n",
       "1  Home Depot            Home & Garden   \n",
       "2        Dell  Computers & Electronics   \n",
       "3         NaN              Video Games   \n",
       "4      Costco               Automotive   \n",
       "\n",
       "                                               title  \\\n",
       "0  [Various Retailers] Gift Card Deals And Discou...   \n",
       "1                           RYOBI 20% coupon barcode   \n",
       "2  Dell G5 - 15\" 144Hz, i7-10750H, 16GB, 512GB, R...   \n",
       "3           Watchdogs 2 PC version free for Everyone   \n",
       "4                 Quickjack 7000slx $200 off - $1300   \n",
       "\n",
       "                                                 url   views  votes  \n",
       "0                                                NaN  365169    317  \n",
       "1                                                NaN    2593     28  \n",
       "2  http://www.jdoqocy.com/click-749547-12105225?u...    2339     15  \n",
       "3  https://register.ubisoft.com/ubisoft-forward-r...   57748    180  \n",
       "4  https://www.costco.ca/quickjack-bl-7000slx-318...   15093     26  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv('rfd_scrape.csv').iloc[:,1:]\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 15 columns):\n",
      "Unnamed: 0         1500 non-null int64\n",
      "author             1500 non-null object\n",
      "creation_date      1500 non-null object\n",
      "expiry             451 non-null object\n",
      "last_reply         1500 non-null object\n",
      "parent_category    920 non-null object\n",
      "price              1017 non-null object\n",
      "replies            1500 non-null int64\n",
      "saving             591 non-null object\n",
      "source             1115 non-null object\n",
      "thread_category    1496 non-null object\n",
      "title              1500 non-null object\n",
      "url                1163 non-null object\n",
      "views              1500 non-null int64\n",
      "votes              1500 non-null int64\n",
      "dtypes: int64(4), object(11)\n",
      "memory usage: 175.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>expiry</th>\n",
       "      <th>last_reply</th>\n",
       "      <th>parent_category</th>\n",
       "      <th>price</th>\n",
       "      <th>replies</th>\n",
       "      <th>saving</th>\n",
       "      <th>source</th>\n",
       "      <th>thread_category</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>451</td>\n",
       "      <td>1500</td>\n",
       "      <td>920</td>\n",
       "      <td>1017</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>591</td>\n",
       "      <td>1115</td>\n",
       "      <td>1496</td>\n",
       "      <td>1500</td>\n",
       "      <td>1163</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1067</td>\n",
       "      <td>1467</td>\n",
       "      <td>79</td>\n",
       "      <td>1415</td>\n",
       "      <td>12</td>\n",
       "      <td>684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306</td>\n",
       "      <td>163</td>\n",
       "      <td>55</td>\n",
       "      <td>1499</td>\n",
       "      <td>1145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>NaN</td>\n",
       "      <td>immad01</td>\n",
       "      <td>Jul 13th, 2020 12:24 pm</td>\n",
       "      <td>July 2, 2020</td>\n",
       "      <td>Jul 13th, 2020 3:17 pm</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>Free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50%</td>\n",
       "      <td>Amazon.ca</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>Ooma Telo Home phone service device $99.99</td>\n",
       "      <td>https://register.ubisoft.com/ubisoft-forward-r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>385</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>231</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.782667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12812.877333</td>\n",
       "      <td>12.895333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>8.658328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.730488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31692.729533</td>\n",
       "      <td>31.407738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>-58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2136.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4106.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10360.750000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2716.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>497207.000000</td>\n",
       "      <td>510.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0   author            creation_date        expiry  \\\n",
       "count   1500.000000     1500                     1500           451   \n",
       "unique          NaN     1067                     1467            79   \n",
       "top             NaN  immad01  Jul 13th, 2020 12:24 pm  July 2, 2020   \n",
       "freq            NaN       39                        3            34   \n",
       "mean      14.500000      NaN                      NaN           NaN   \n",
       "std        8.658328      NaN                      NaN           NaN   \n",
       "min        0.000000      NaN                      NaN           NaN   \n",
       "25%        7.000000      NaN                      NaN           NaN   \n",
       "50%       14.500000      NaN                      NaN           NaN   \n",
       "75%       22.000000      NaN                      NaN           NaN   \n",
       "max       29.000000      NaN                      NaN           NaN   \n",
       "\n",
       "                    last_reply          parent_category price      replies  \\\n",
       "count                     1500                      920  1017  1500.000000   \n",
       "unique                    1415                       12   684          NaN   \n",
       "top     Jul 13th, 2020 3:17 pm  Computers & Electronics  Free          NaN   \n",
       "freq                         5                      385    16          NaN   \n",
       "mean                       NaN                      NaN   NaN    48.782667   \n",
       "std                        NaN                      NaN   NaN   133.730488   \n",
       "min                        NaN                      NaN   NaN     0.000000   \n",
       "25%                        NaN                      NaN   NaN     5.000000   \n",
       "50%                        NaN                      NaN   NaN    14.000000   \n",
       "75%                        NaN                      NaN   NaN    41.000000   \n",
       "max                        NaN                      NaN   NaN  2716.000000   \n",
       "\n",
       "       saving     source          thread_category  \\\n",
       "count     591       1115                     1496   \n",
       "unique    306        163                       55   \n",
       "top       50%  Amazon.ca  Computers & Electronics   \n",
       "freq       32        231                      177   \n",
       "mean      NaN        NaN                      NaN   \n",
       "std       NaN        NaN                      NaN   \n",
       "min       NaN        NaN                      NaN   \n",
       "25%       NaN        NaN                      NaN   \n",
       "50%       NaN        NaN                      NaN   \n",
       "75%       NaN        NaN                      NaN   \n",
       "max       NaN        NaN                      NaN   \n",
       "\n",
       "                                             title  \\\n",
       "count                                         1500   \n",
       "unique                                        1499   \n",
       "top     Ooma Telo Home phone service device $99.99   \n",
       "freq                                             2   \n",
       "mean                                           NaN   \n",
       "std                                            NaN   \n",
       "min                                            NaN   \n",
       "25%                                            NaN   \n",
       "50%                                            NaN   \n",
       "75%                                            NaN   \n",
       "max                                            NaN   \n",
       "\n",
       "                                                      url          views  \\\n",
       "count                                                1163    1500.000000   \n",
       "unique                                               1145            NaN   \n",
       "top     https://register.ubisoft.com/ubisoft-forward-r...            NaN   \n",
       "freq                                                    2            NaN   \n",
       "mean                                                  NaN   12812.877333   \n",
       "std                                                   NaN   31692.729533   \n",
       "min                                                   NaN     117.000000   \n",
       "25%                                                   NaN    2136.250000   \n",
       "50%                                                   NaN    4106.500000   \n",
       "75%                                                   NaN   10360.750000   \n",
       "max                                                   NaN  497207.000000   \n",
       "\n",
       "              votes  \n",
       "count   1500.000000  \n",
       "unique          NaN  \n",
       "top             NaN  \n",
       "freq            NaN  \n",
       "mean      12.895333  \n",
       "std       31.407738  \n",
       "min      -58.000000  \n",
       "25%        1.000000  \n",
       "50%        4.000000  \n",
       "75%       14.000000  \n",
       "max      510.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creation_date :  <class 'str'>\n",
      "expiry :  <class 'float'>\n",
      "last_reply :  <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Copy of raw data set\n",
    "df = df_raw.copy()\n",
    "\n",
    "# List of tuples: (column name, column dtype)\n",
    "col_dtypes = [(col, type(x)) for x,col in zip(df.iloc[0], df.columns)]\n",
    "\n",
    "# Print tuple for columns containing dates\n",
    "for col in col_dtypes:\n",
    "    if col[0] in ['creation_date', 'last_reply', 'expiry']:\n",
    "        print(col[0], ': ', col[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the columns are formatted as datetime. To facilitate working with the dates, we will convert them to datetime. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert date columns to datetime dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_datetime(column: str) -> pd.Series:\n",
    "    \"\"\"Converts a column of format \"%b %d, %Y %I:%M %p\" from string to date-time\n",
    "    \n",
    "    Args:\n",
    "    date_column - name of column with dates encoded as strings\n",
    "    \n",
    "    Returns:\n",
    "    Column elements converted to datetime in a pandas.Series object\n",
    "    \"\"\"    \n",
    "    # Superfluous characters removed\n",
    "    column_clean = df[column].str.replace(\"st\",\"\").str.replace(\"nd\",\"\").str.replace(\"rd\",\"\").str.replace(\"th\",\"\").str.strip()\n",
    "    \n",
    "    # Check for correct length of cleaned column\n",
    "    column_len = len(column_clean)\n",
    "    print(\"Cleaned and original column are of equal lenght: \", column_len == len(df[column]), \"\\n\")\n",
    "    \n",
    "    # Convert from format \"%b %d, %Y %I:%M %p\" to datetime\n",
    "    date_column = []\n",
    "    try:\n",
    "        date_column = column_clean.apply(lambda x : datetime.datetime.strptime(str(x), \"%b %d, %Y %I:%M %p\"))\n",
    "    except: \n",
    "        print(\"\\\"%b %d, %Y %I:%M %p\\\" is incorrect format\")\n",
    "        pass\n",
    "    \n",
    "    # Convert from format \"%B %d, %Y\" to datetime\n",
    "    for date in df[column]:\n",
    "        if date is not np.nan:\n",
    "            try:\n",
    "                date_column.append(datetime.datetime.strptime(date, \"%B %d, %Y\"))\n",
    "            except: \n",
    "                print(\"\\\"%B %d, %Y\\\" is incorrect format for\", date)\n",
    "                break\n",
    "        else: \n",
    "            date_column.append(None)\n",
    "    \n",
    "    if len(date_column) != column_len:\n",
    "        print(\"\\n\", \"Incorrect column length!\\n\")\n",
    "    else:\n",
    "        print(\"\\n\", \"Column has expected length!\\n\")\n",
    "    \n",
    "    return pd.Series(date_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and original column are of equal lenght:  True \n",
      "\n",
      "\"%B %d, %Y\" is incorrect format for Jan 1st, 2020 8:32 pm\n",
      "\n",
      " Column has expected length!\n",
      "\n",
      "99    2020-07-08 17:53:00\n",
      "100   2020-07-11 20:38:00\n",
      "101   2020-06-12 12:22:00\n",
      "102   2020-07-13 11:35:00\n",
      "103   2020-04-23 13:01:00\n",
      "104   2020-07-13 11:58:00\n",
      "Name: creation_date, dtype: datetime64[ns] \n",
      "\n",
      "99       Jul 8th, 2020 5:53 pm\n",
      "100     Jul 11th, 2020 8:38 pm\n",
      "101    Jun 12th, 2020 12:22 pm\n",
      "102    Jul 13th, 2020 11:35 am\n",
      "103     Apr 23rd, 2020 1:01 pm\n",
      "104    Jul 13th, 2020 11:58 am\n",
      "Name: creation_date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# creation_date column converted to datetime\n",
    "creation_date = to_datetime('creation_date')\n",
    "\n",
    "# Compare random slice of original and converted column\n",
    "print(creation_date.iloc[99:105], \"\\n\")\n",
    "print(df.loc[99:104, 'creation_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and original column are of equal lenght:  True \n",
      "\n",
      "\"%B %d, %Y\" is incorrect format for Jul 13th, 2020 3:25 pm\n",
      "\n",
      " Column has expected length!\n",
      "\n",
      "208   2020-07-12 20:04:00\n",
      "209   2020-07-12 19:53:00\n",
      "210   2020-07-12 19:47:00\n",
      "211   2020-07-12 19:43:00\n",
      "212   2020-07-12 19:28:00\n",
      "213   2020-07-12 19:28:00\n",
      "214   2020-07-12 19:10:00\n",
      "Name: last_reply, dtype: datetime64[ns] \n",
      "\n",
      "208    Jul 12th, 2020 8:04 pm\n",
      "209    Jul 12th, 2020 7:53 pm\n",
      "210    Jul 12th, 2020 7:47 pm\n",
      "211    Jul 12th, 2020 7:43 pm\n",
      "212    Jul 12th, 2020 7:28 pm\n",
      "213    Jul 12th, 2020 7:28 pm\n",
      "214    Jul 12th, 2020 7:10 pm\n",
      "Name: last_reply, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# last_reply column converted to datetime\n",
    "last_reply = to_datetime('last_reply')\n",
    "\n",
    "# Print original and new column for comparison\n",
    "print(last_reply.iloc[208:215], \"\\n\")\n",
    "print(df.loc[208:214, 'last_reply'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(to_datetime('expiry').iloc[50:57], \"\\n\")\n",
    "# print(df.loc[50:56, 'expiry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last logging:  \n",
    "Date:  **Augu 24, 2020**    \n",
    "date is not np.nan:  True  \n",
    "dtype of date:  <class 'str'>  \n",
    "\"%B %d, %Y\" is incorrect format for Augu 24, 2020  \n",
    "\n",
    "From the last logging, it becomes apparent that `st` has been removed from August due to the use of str.replace() in the to_datetime() function. This is not an issue for the columns with a `%b` format for months. The solution is to use the uncleaned data for the `expiry` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and original column are of equal lenght:  True \n",
      "\n",
      "\"%b %d, %Y %I:%M %p\" is incorrect format\n",
      "\n",
      " Column has expected length!\n",
      "\n",
      "50   2020-09-08\n",
      "51   2020-07-23\n",
      "52   2020-07-26\n",
      "53          NaT\n",
      "54          NaT\n",
      "55          NaT\n",
      "56          NaT\n",
      "dtype: datetime64[ns] \n",
      "\n",
      "50    September 8, 2020\n",
      "51        July 23, 2020\n",
      "52        July 26, 2020\n",
      "53                  NaN\n",
      "54                  NaN\n",
      "55                  NaN\n",
      "56                  NaN\n",
      "Name: expiry, dtype: object\n"
     ]
    }
   ],
   "source": [
    "expiry = to_datetime('expiry')\n",
    "print(expiry.iloc[50:57], \"\\n\")\n",
    "print(df.loc[50:56, 'expiry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The to_datetime() function appears to correctly convert each of the columns. The results can now be used in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>expiry</th>\n",
       "      <th>last_reply</th>\n",
       "      <th>parent_category</th>\n",
       "      <th>price</th>\n",
       "      <th>replies</th>\n",
       "      <th>saving</th>\n",
       "      <th>source</th>\n",
       "      <th>thread_category</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>trystee</td>\n",
       "      <td>2020-01-01 20:32:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-07-13 15:25:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>[Various Retailers] Gift Card Deals And Discou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365169</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yellowmp5</td>\n",
       "      <td>2020-07-13 13:29:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-07-13 15:23:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "      <td>RYOBI 20% coupon barcode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2593</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>phoreoneone</td>\n",
       "      <td>2020-07-13 12:34:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-07-13 15:23:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dell</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>Dell G5 - 15\" 144Hz, i7-10750H, 16GB, 512GB, R...</td>\n",
       "      <td>http://www.jdoqocy.com/click-749547-12105225?u...</td>\n",
       "      <td>2339</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Blackdove77</td>\n",
       "      <td>2020-07-06 12:49:00</td>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>2020-07-13 15:23:00</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413</td>\n",
       "      <td>100%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Video Games</td>\n",
       "      <td>Watchdogs 2 PC version free for Everyone</td>\n",
       "      <td>https://register.ubisoft.com/ubisoft-forward-r...</td>\n",
       "      <td>57748</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>hkhorace</td>\n",
       "      <td>2020-07-06 09:56:00</td>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>2020-07-13 15:22:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1300</td>\n",
       "      <td>77</td>\n",
       "      <td>$200 off</td>\n",
       "      <td>Costco</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Quickjack 7000slx $200 off - $1300</td>\n",
       "      <td>https://www.costco.ca/quickjack-bl-7000slx-318...</td>\n",
       "      <td>15093</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       author       creation_date     expiry          last_reply  \\\n",
       "0           0      trystee 2020-01-01 20:32:00        NaT 2020-07-13 15:25:00   \n",
       "1           1    yellowmp5 2020-07-13 13:29:00        NaT 2020-07-13 15:23:00   \n",
       "2           2  phoreoneone 2020-07-13 12:34:00        NaT 2020-07-13 15:23:00   \n",
       "3           3  Blackdove77 2020-07-06 12:49:00 2020-07-19 2020-07-13 15:23:00   \n",
       "4           4     hkhorace 2020-07-06 09:56:00 2020-07-12 2020-07-13 15:22:00   \n",
       "\n",
       "           parent_category price  replies    saving      source  \\\n",
       "0                      NaN   NaN      672       NaN         NaN   \n",
       "1                      NaN   NaN       26       NaN  Home Depot   \n",
       "2                      NaN   NaN       23       NaN        Dell   \n",
       "3  Computers & Electronics   NaN      413      100%         NaN   \n",
       "4                      NaN  1300       77  $200 off      Costco   \n",
       "\n",
       "           thread_category                                              title  \\\n",
       "0                Groceries  [Various Retailers] Gift Card Deals And Discou...   \n",
       "1            Home & Garden                           RYOBI 20% coupon barcode   \n",
       "2  Computers & Electronics  Dell G5 - 15\" 144Hz, i7-10750H, 16GB, 512GB, R...   \n",
       "3              Video Games           Watchdogs 2 PC version free for Everyone   \n",
       "4               Automotive                 Quickjack 7000slx $200 off - $1300   \n",
       "\n",
       "                                                 url   views  votes  \n",
       "0                                                NaN  365169    317  \n",
       "1                                                NaN    2593     28  \n",
       "2  http://www.jdoqocy.com/click-749547-12105225?u...    2339     15  \n",
       "3  https://register.ubisoft.com/ubisoft-forward-r...   57748    180  \n",
       "4  https://www.costco.ca/quickjack-bl-7000slx-318...   15093     26  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign datetime columns to DataFrame\n",
    "df.expiry = expiry\n",
    "df.last_reply = last_reply\n",
    "df.creation_date = creation_date\n",
    "\n",
    "# Verify dates\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing data: `source`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Various Retailers] Gift Card Deals And Discou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>RYOBI 20% coupon barcode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Dell</td>\n",
       "      <td>Dell G5 - 15\" 144Hz, i7-10750H, 16GB, 512GB, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Watchdogs 2 PC version free for Everyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Costco</td>\n",
       "      <td>Quickjack 7000slx $200 off - $1300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                              title\n",
       "0         NaN  [Various Retailers] Gift Card Deals And Discou...\n",
       "1  Home Depot                           RYOBI 20% coupon barcode\n",
       "2        Dell  Dell G5 - 15\" 144Hz, i7-10750H, 16GB, 512GB, R...\n",
       "3         NaN           Watchdogs 2 PC version free for Everyone\n",
       "4      Costco                 Quickjack 7000slx $200 off - $1300"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, ['source', 'title']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible, that users simply forgot to include the source of the deal. We will check if missing sources are mentioned in the corresponding title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique sources:  163\n",
      "385 missing values in source column\n"
     ]
    }
   ],
   "source": [
    "# Set of entries in 'source' column\n",
    "retailer_set = set(df['source'].dropna())\n",
    "print(\"Number of unique sources: \", len(retailer_set))\n",
    "print(df.source.isnull().sum(), \"missing values in source column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The large number of unique sources is promising! \n",
    "\n",
    "Next we will use the set previously created to itterate through the titles an check if any of the unique source names are present. If a source name from the set is found in `title` and no value is found in the corresponding `source` column, then the index as well as the source name are saved in the `replace` dictinoary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacements found in 'title': 53\n"
     ]
    }
   ],
   "source": [
    "replace_dict = {} # key: index; value: retailer name to replace missing source value at index\n",
    "# found_in_title = {} # keys: retailer name; values: number of times name was found in a post-title\n",
    "# source_in_title = [] # names of retailers mentioned in at least one title\n",
    "# replaceable_value_count = 0\n",
    "\n",
    "# Iterate throuh set of unique values from source source column\n",
    "for retailer in retailer_set:\n",
    "    \"\"\"Fill replace dictioray with indecies and source names. Entries are made\n",
    "    when a source name is found in the title column while the corresponding source entry\n",
    "    is empty.\"\"\"\n",
    "    \n",
    "    # Iterate through 'source' and 'title' columns row-by-row\n",
    "    # Generate boolean array: True if unique source name (retailer) found in \"title\" and \"source\" is np.nan\n",
    "    source_missing_and_in_title = np.array([retailer in title \n",
    "                                     if source is np.nan else False\n",
    "                                     for title,source in zip(df.title, df.source)])\n",
    "    \n",
    "    # Indecies for which source_missing_and_in_title is True\n",
    "    replacement_indicies = np.where(source_missing_and_in_title == True)[0]\n",
    "    # Fill \"replace\" dictionary\n",
    "    for index in replacement_indicies:\n",
    "        if index not in replace_dict.keys():\n",
    "            replace_dict[index] = retailer\n",
    "\n",
    "print(\"Replacements found in 'title':\", len(replace_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "53 missing sources can be replaced by information found in the title. We will use the indecies and values stored in `replace_dict` to replace the appropriate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing source values before replacement: 385\n",
      "Missing source values after replacement: 332\n",
      "53 missing source records have been replaced!\n"
     ]
    }
   ],
   "source": [
    "source_list = list(df.source)\n",
    "missing_start = sum([x is np.nan for x in source_list])\n",
    "print(\"Missing source values before replacement:\", missing_start)\n",
    "\n",
    "for replace_source in replace.items():\n",
    "    source_list[replace_source[0]] = replace_source[1]\n",
    "\n",
    "missing_end = sum([x is np.nan for x in source_list])\n",
    "print(\"Missing source values after replacement:\", missing_end)\n",
    "replaced_count = missing_start-missing_end\n",
    "print(replaced_count, \"missing source records have been replaced!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 53 identified `source` records have been replaced with apporiate names of retailers found in the corrseponding `title` column. The new `source` column can now replace the old one.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values as expected: True\n"
     ]
    }
   ],
   "source": [
    "df.source = source_list\n",
    "print(\"Number of missing values as expected:\", (df.source.isnull().sum() == missing_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further substitutions for missing `source` values may be found in the `url` column. The objective is to extract company names from the urls and use them to further replace missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 missing source values have corresponding urls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                   NaN\n",
       "3     https://register.ubisoft.com/ubisoft-forward-r...\n",
       "17    http://go.redirectingat.com?id=2927x594702&amp...\n",
       "19    http://click.linksynergy.com/deeplink?id=CAqD7...\n",
       "22        https://www.costco.ca/.product.100476333.html\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'url' entries of rows with missing source values\n",
    "url_replacement = df[df.source.isnull()].url\n",
    "print(url_replacement.notnull().sum(), \"missing source values have corresponding urls\")\n",
    "url_replacement.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The urls need to be split and cleaned to extract the name of the organisation. The final cleaned values and their corresponding indicies in the DataFrame will be stores in the `clean_urls` disctionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: nan, 3: ['register', 'ubisoft', 'com'], 17: ['go', 'redirectingat', 'com'], 19: ['click', 'linksynergy', 'com'], 22: ['costco', 'ca'], 23: nan, 27: ['activebaby', 'ca'], 41: ['classic', 'avantlink', 'com'], 45: ['awin1', 'com'], 46: nan, 49: ['awin1', 'com'], 54: ['ebox', 'ca'], 59: ['awin1', 'com'], 62: ['store', 'insta360', 'com'], 63: ['amazon', 'ca'], 65: ['costco', 'ca'], 71: ['cityfone', 'net'], 77: ['alltrails', 'com'], 80: ['costco', 'ca'], 81: ['click', 'linksynergy', 'com'], 84: nan, 87: ['econsumer', 'equifax', 'ca'], 91: nan, 94: nan, 103: nan, 113: ['amazon', 'ca'], 122: nan, 141: ['svpsports', 'ca'], 147: ['amazon', 'ca'], 151: nan, 152: ['bcfasteners', 'com'], 156: ['costco', 'ca'], 157: ['staplescanada', '4u8mqw', 'net'], 165: nan, 166: ['register', 'ubisoft', 'com'], 168: ['apps', 'apple', 'com'], 169: ['amazon', 'ca'], 171: ['amazon', 'ca'], 172: ['mailchi', 'mp'], 178: ['amazon', 'ca'], 180: ['bccamera', 'com'], 183: ['amazon', 'ca'], 187: ['tkqlhce', 'com'], 191: ['amazon', 'ca'], 193: nan, 196: nan, 199: ['amazon', 'ca'], 205: ['pi-co', 'ca'], 207: ['awin1', 'com'], 211: ['cdkeys', 'com'], 215: ['go', 'redirectingat', 'com'], 230: ['kits', 'com'], 235: ['the-home-depot-ca', 'pxf', 'io'], 237: ['signup', 'easynews', 'com'], 238: ['tsc', 'ca'], 244: nan, 247: ['amazon', 'ca'], 248: ['amazon', 'ca'], 250: ['fadedsoul', 'com'], 251: ['apfco', 'com'], 253: ['the-home-depot-ca', 'pxf', 'io'], 254: nan, 255: ['canadiantire', 'ca'], 257: ['levis-canada', 'sjv', 'io'], 258: ['canadiantire', 'ca'], 260: ['fujifilmprintlife', 'ca'], 268: ['mysimplemarketplace', 'com'], 272: ['tanguay', 'ca'], 275: ['amazon', 'ca'], 277: ['scotiabank', 'com'], 280: ['amazon', 'ca'], 285: nan, 288: ['cdkeys', 'com'], 298: nan, 299: nan, 301: ['awin1', 'com'], 319: ['ca', 'miele', 'ca'], 323: nan, 328: nan, 329: nan, 330: ['cdkeys', 'com'], 332: ['kqzyfj', 'com'], 334: nan, 338: ['drop', 'com'], 339: ['svpsports', 'ca'], 344: ['rakuten', 'ca'], 345: ['outterlimits', 'com'], 350: ['go', 'redirectingat', 'com'], 351: ['playolg', 'ca'], 353: ['click', 'linksynergy', 'com'], 359: ['click', 'linksynergy', 'com'], 366: ['amazon', 'ca'], 367: ['getmyoffers', 'ca'], 368: ['canex', 'ca'], 371: nan, 376: ['mobvoi', 'com'], 381: ['costco', 'ca'], 385: ['kqzyfj', 'com'], 388: ['store', 'playstation', 'com'], 399: ['click', 'linksynergy', 'com'], 400: nan, 407: ['elac', 'com'], 411: ['facebook', 'com'], 412: nan, 416: nan, 417: nan, 418: nan, 419: ['wellwise', 'ca'], 436: nan, 438: ['amazon', 'ca'], 440: ['ampli', 'ca'], 443: ['burton', 'com'], 451: ['tkqlhce', 'com'], 453: ['cdkeys', 'com'], 458: ['store', 'playstation', 'com'], 463: ['altimatel', 'com'], 464: ['fastchargedocks', 'com'], 465: nan, 471: ['shop', 'lindt', 'ca'], 472: ['formula1', 'com'], 473: ['gotransit', 'com'], 475: ['carrytel', 'ca'], 476: nan, 480: ['the-home-depot-ca', 'pxf', 'io'], 482: nan, 493: ['try', 'fender', 'com'], 494: ['ionos', 'ca'], 498: ['simplii', 'com'], 499: ['amazon', 'ca'], 502: nan, 504: ['costco', 'ca'], 505: ['go', 'redirectingat', 'com'], 508: ['costco', 'ca'], 509: ['wellwise', 'ca'], 512: nan, 514: ['ninjakitchen', 'com'], 515: nan, 526: ['amazon', 'ca'], 527: nan, 555: ['bestbuyca', 'o93x', 'net'], 560: ['anrdoezrs', 'net'], 562: ['sherwin-williams', 'ca'], 576: ['aeroplan-bg-sso', 'points', 'com'], 578: ['bit', 'ly'], 593: ['anrdoezrs', 'net'], 606: ['click', 'linksynergy', 'com'], 608: ['googleadservices', 'com'], 610: ['kqzyfj', 'com'], 618: ['metopera', 'org'], 620: ['billing', 'frugalusenet', 'com'], 622: ['amazon', 'ca'], 624: ['awin1', 'com'], 628: ['therecroom', 'com'], 630: ['decathalon-canada', 'mkr3', 'net'], 639: ['oxio', 'ca'], 643: ['bestbuyca', 'o93x', 'net'], 645: ['amazon', 'ca'], 649: ['speakout7eleven', 'ca'], 660: ['uberats', 'ca'], 664: ['kelloggsgrocerycash', 'ca'], 666: ['click', 'linksynergy', 'com'], 670: ['edifier', 'com'], 674: nan, 675: ['ca', 'manscaped', 'com'], 678: ['click', 'linksynergy', 'com'], 680: nan, 681: ['click', 'linksynergy', 'com'], 685: ['awin1', 'com'], 689: nan, 697: ['play', 'google', 'com'], 705: ['everyonerides', 'org'], 706: ['detourcoffee', 'com'], 714: ['oculus', 'com'], 716: ['americanexpress', 'com'], 723: nan, 727: ['Www', 'nbc', 'ca'], 728: ['cashback', 'highinterestsavings', 'ca'], 735: nan, 740: ['lenovo', 'evyy', 'net'], 747: ['go', 'redirectingat', 'com'], 751: ['rallyforrestaurants', 'ca'], 754: ['oculus', 'com'], 756: ['idrinkcoffee', 'com'], 763: nan, 765: ['cosmeticscompanystore', 'com'], 766: ['napoleon', 'com'], 770: ['brampton', 'ca'], 771: ['treadmillfactory', 'ca'], 773: ['go', 'redirectingat', 'com'], 775: nan, 777: ['awin1', 'com'], 779: ['thecubenet', 'com'], 786: ['dispatchcoffee', 'ca'], 788: ['cwbeggs', 'com'], 789: ['click', 'linksynergy', 'com'], 796: ['lostcraft', 'ca'], 802: ['try', 'tidal', 'com'], 803: ['canada', 'bissell', 'com'], 807: nan, 809: ['go', 'redirectingat', 'com'], 817: ['go', 'redirectingat', 'com'], 823: ['store', 'playstation', 'com'], 824: ['store', 'playstation', 'com'], 825: nan, 827: ['radpowerbikes', 'ca'], 830: ['fitnessavenue', 'ca'], 833: nan, 837: ['enbridgesmartsavings', 'com'], 839: nan, 853: ['us', 'shop', 'battle', 'net'], 857: ['play', 'google', 'com'], 865: ['accounts', 'usenetserver', 'com'], 867: ['edifier', 'com'], 876: ['poppacorn', 'ca'], 878: ['amazon', 'com'], 879: ['amazon', 'ca'], 880: ['sportium', 'ca'], 882: ['mcgillpersonalfinance', 'com'], 884: ['uhaul', 'com'], 885: ['ecscoffee', 'com'], 889: ['teasante', 'com'], 891: ['thermoworks', 'com'], 895: nan, 896: nan, 900: ['bonusboom', 'airmiles', 'ca'], 905: ['outterlimits', 'com'], 908: ['completeequipment', 'ca'], 911: ['walmartphotocentre', 'ca'], 916: ['the-home-depot-ca', 'pxf', 'io'], 917: ['avantlink', 'ca'], 922: ['bestbuyca', 'o93x', 'net'], 928: nan, 932: ['ugo', 'ca'], 935: ['go', 'redirectingat', 'com'], 943: nan, 947: ['harryrosen', 'com'], 952: nan, 955: ['luckymobile', 'ca'], 962: ['aeroplan', 'com'], 964: nan, 974: ['waterloobrewing', 'com'], 980: ['gibbyselectronicsupermarket', 'ca'], 990: nan, 993: ['twitter', 'com'], 995: ['awin1', 'com'], 1000: ['deezer', 'com'], 1001: ['click', 'linksynergy', 'com'], 1006: ['software', 'pcworld', 'com'], 1013: ['dicksonbbq', 'com'], 1015: nan, 1019: ['amazon', 'ca'], 1023: ['fitnessavenue', 'ca'], 1032: ['go', 'redirectingat', 'com'], 1049: ['edifier', 'com'], 1051: ['amazon', 'ca'], 1058: ['stacksocial', 'com'], 1073: ['awin1', 'com'], 1089: ['apps', 'apple', 'com'], 1093: ['razer', 'com'], 1102: nan, 1108: ['store', 'playstation', 'com'], 1118: ['tkqlhce', 'com'], 1128: ['play', 'google', 'com'], 1144: ['store', 'playstation', 'com'], 1146: ['brownsshoes', 'com'], 1149: ['amazon', 'ca'], 1152: ['lecreuset', 'ca'], 1163: ['news', 'xbox', 'com'], 1168: nan, 1169: ['store', 'steampowered', 'com'], 1181: ['google', 'com'], 1183: ['storefront', 'points', 'com'], 1184: nan, 1191: nan, 1198: ['awin1', 'com'], 1216: ['shoprbc', 'com'], 1218: ['go', 'redirectingat', 'com'], 1223: ['cpapoutlet', 'ca'], 1225: ['circlekgames', 'ca'], 1228: ['humblebundle', 'com'], 1243: nan, 1248: ['store', 'playstation', 'com'], 1253: ['scholastic', 'ca'], 1259: ['go', 'redirectingat', 'com'], 1261: nan, 1266: nan, 1270: nan, 1277: ['warriorsandwonders', 'com'], 1278: ['nintendo', 'com'], 1280: ['ituonline', 'com'], 1282: ['facebook', 'com'], 1298: ['getsuperwrap', 'com'], 1307: ['play', 'google', 'com'], 1311: ['beanwise', 'ca'], 1321: nan, 1331: ['docs', 'google', 'com'], 1336: nan, 1347: ['ca', 'norlanglass', 'com'], 1364: ['gog', 'com'], 1370: nan, 1377: nan, 1386: ['usenetprime', 'com'], 1389: ['store', 'asuswebstorage', 'com'], 1392: ['pntrac', 'com'], 1393: ['irobot', 'ca'], 1399: ['instagram', 'com'], 1400: ['doordashca', 'launchgiftcards', 'com'], 1414: ['store', 'playstation', 'com'], 1415: ['hellodemello', 'com'], 1423: ['awin1', 'com'], 1424: ['detourcoffee', 'com'], 1439: nan, 1441: ['weber', 'com'], 1444: ['humblebundle', 'com'], 1448: ['atlas-machinery', 'com'], 1449: ['kits', 'com'], 1456: ['newsgroupdirect', 'com'], 1457: ['100dollar', 'darkhorseapp', 'net'], 1458: ['amazon', 'ca'], 1459: ['taappliance', 'com'], 1461: ['consumer', 'huawei', 'com'], 1465: nan, 1468: nan, 1471: ['viofo', 'com'], 1472: ['cdkeys', 'com'], 1473: ['play', 'google', 'com'], 1475: ['shecodes', 'io'], 1483: ['go', 'redirectingat', 'com'], 1485: ['community', 'stadia', 'com'], 1486: ['pc-canada', 'com'], 1494: nan, 1498: ['go', 'redirectingat', 'com']}\n"
     ]
    }
   ],
   "source": [
    "clean_urls = {} # key: index in df, value: cleaned url\n",
    "indicies = url_replacement.index\n",
    "\n",
    "for url in zip(indicies, url_replacement):\n",
    "    index = url[0]\n",
    "    replacement_url = url[1]\n",
    "    \n",
    "    # Clean if url value not missing\n",
    "    if replacement_url is not np.nan:\n",
    "        url_root = replacement_url.split(\"//\")[1].split(\"/\")[0].split(\"?\")[0].replace(\"www.\", \"\")\n",
    "        removed_domain = url_root.split(\".\")\n",
    "        clean_urls[index] = removed_domain\n",
    "    else:\n",
    "        clean_urls[index] = np.nan\n",
    "        \n",
    "print(clean_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to identify the company names from the url splits observed in the print above.\n",
    "The patterns shown in the table will facilitate this process. This is an oversimplification and will lead to some false extractions but the number of errors should be minimal.\n",
    "\n",
    "|Condition| Pattern|\n",
    "|---|---|\n",
    "|Lists length 2| company name is at index 0|\n",
    "|Lists length 3 and domain com, ca, or net| name is at index 1|\n",
    "|List length 3 and domain io| name is at index 0| \n",
    "|List length 4| no identifiable name|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_url_final = clean_urls.copy()\n",
    "\n",
    "for item in clean_url_final.items():\n",
    "    index = item[0]\n",
    "    url_split = item[1]\n",
    "    try:\n",
    "        if len(url_split) == 2:\n",
    "             # name at index 0\n",
    "            clean_url_final[index] = url_split[0].title()\n",
    "        \n",
    "        elif ((len(url_split) == 3) \n",
    "                        and ((url_split[-1] == \"com\") \n",
    "                                 or (url_split[-1] == \"ca\") \n",
    "                                 or (url_split[-1] == \"ca\"))):\n",
    "            # name at index 1\n",
    "            clean_url_final[index] = url_split[1].title()\n",
    "        \n",
    "        elif ((len(url_split) == 3) \n",
    "                        and (url_split[-1] == \"io\")):\n",
    "             # name at index 0\n",
    "            clean_url_final[index] = url_split[0].title()\n",
    "        else: \n",
    "              clean_url_final[index] = np.nan\n",
    "    except: value = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing source values remaining:  78\n"
     ]
    }
   ],
   "source": [
    "# Add url-derived company names to DataFrame\n",
    "df.loc[list(clean_url_final.keys()),'source'] = list(clean_url_final.values())\n",
    "print(\"Missing source values remaining: \", df.source.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing data: `price`\n",
    "\n",
    "Users may have forgoten to tag prices associated with the deals they posted. We will verify if their are any `$` signs in the title for those rows that have missing price values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483 missing values in 'price' column\n",
      "246 missing prices have '$' signs in the title\n"
     ]
    }
   ],
   "source": [
    "missing_prices_df = df[df.price.isnull()]\n",
    "price_in_title = [\"$\" in title for title in missing_prices_df.title]\n",
    "print(df.price.isnull().sum(), \"missing values in 'price' column\")\n",
    "print(sum(price_in_title), \"missing prices have '$' signs in the title\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dell G5 - 15\" 144Hz, i7-10750H, 16GB, 512GB, RTX 2060 $1,549 ($1425/$1285 Rakuten/Rakuten+Uni)',\n",
       " 'iTunes gift cards - $21.49 for $25 | $84.99 for $100 | $167.99 for $200 (Members only)',\n",
       " 'Lenovo Duet Chromebook 2-in-1: $399 - preorder',\n",
       " '[Uplay/Steam] Far Cry 5 (11.99$) - Far Cry 4 (7.99$) - Far Cry 3 (3.90$)',\n",
       " 'Ebay - Take $5 off minimum purchase of $5.01 YMMV',\n",
       " 'Samsung Galaxy S10 Lite (6.7\", 128GB, 8GB, SD855, 4500mah) US$431 / CAD$585 (and Note 10 Lite CAD$572)',\n",
       " 'Amex Business Platinum: $250 credit for $250 spend at dell.ca',\n",
       " 'Shopping.ca Gift Card by Ivanho Cambridge - Spend at least $100 and Earn $20 credit. Up to 3 times - YMMV',\n",
       " 'Samsung CRG9 - 49inch 1440p 120hrz monitor $1299 Best Buy',\n",
       " 'Book Outlet - Many Low Prices on Books (Free Shipping Over $45 & 16% Off)']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first 10 title to evaluate if the missing price could be substituted\n",
    "replacement_titles = missing_prices_df[price_in_title].title\n",
    "[title for title in replacement_titles][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible replacements: 246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2                           [$1,549, $1425, $1285]\n",
       "12      [$21.49, $25, $84.99, $100, $167.99, $200]\n",
       "16                                          [$399]\n",
       "17                          [11.99$, 7.99$, 3.90$]\n",
       "23                                         [$5.01]\n",
       "                           ...                    \n",
       "1465                                         [$49]\n",
       "1485                                        [$139]\n",
       "1488                                    [$60, $20]\n",
       "1493                                    [$10, $14]\n",
       "1498                            [$169.95, $199.95]\n",
       "Name: title, Length: 246, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = \"[$]+[.,]*\\d+[.,]*\\d+\"\\\n",
    "        \"|[.,]*\\d+[.,]*\\d+[$]+\"\\\n",
    "        \"|[a-zA-Z]+[$]+[.,]*\\d+[.,]*\\d+\"\n",
    "price_replacements = replacement_titles.str.findall(regex)\n",
    "print(\"Number of possible replacements:\", len(price_replacements))\n",
    "price_replacements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll assume the first element in each list is most relevant and use it to replace missing price values. Some inaccuracies are likely to occure but the estimates should be reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231 replacements found.\n"
     ]
    }
   ],
   "source": [
    "replacement_dict = {} # key: index; value: price to replace missing value at index\n",
    "\n",
    "# Iterate through price lists found in price_replacements and corresonding indecies in DataFrame\n",
    "for replacement in zip(price_replacements, list(price_replacements.index)):\n",
    "    price_list = replacement[0]\n",
    "    index = replacement[1]\n",
    "    if price_list != []:\n",
    "        price = price_list[0]\n",
    "        price_clean = (re.search(r\"\\d+[.,]*\\d+\", price)).group().replace(\",\",\"\")\n",
    "        replacement_dict[index] = price_clean\n",
    "        \n",
    "print(len(replacement_dict), \"replacements found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining missing values: 252\n"
     ]
    }
   ],
   "source": [
    "# Replace missing values\n",
    "df.loc[list(replacement_dict.keys()), 'price'] = list(replacement_dict.values())\n",
    "print(\"Remaining missing values:\", df.price.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Statistics' from 'math' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-16d35d5a8ad7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStatistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mStatistics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Statistics' from 'math' (unknown location)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
